./
├── README.md
├── audit_dvc_usage.py*
├── audit_out/
│   ├── entry_scripts.csv
│   ├── report_orphans.csv
│   ├── summary.json
│   ├── unused_scripts.csv
│   └── used_scripts.csv
├── backup_eval/
│   ├── confusion.csv
│   ├── confusion.png
│   ├── confusion_normalized.csv
│   ├── confusion_normalized.png
│   └── metrics.json
├── configs/
│   └── aspects_en.json
├── data/
│   ├── cache/
│   │   └── product_images/
│   │       └── thumbs/
│   │           ├── P107306.webp
│   │           ├── P114902.webp
│   │           ├── P12045.webp
│   │           ├── P122651.webp
│   │           ├── P122661.webp
│   │           ├── P122718.webp
│   │           ├── P122727.webp
│   │           ├── P122762.webp
│   │           ├── P122767.webp
│   │           ├── P122774.webp
│   │           ├── P122782.webp
│   │           ├── P122876.webp
│   │           ├── P122881.webp
│   │           ├── P122882.webp
│   │           ├── P122900.webp
│   │           ├── P12295.webp
│   │           ├── P12336.webp
│   │           ├── P12573.webp
│   │           ├── P126301.webp
│   │           ├── P139000.webp
│   │           ├── P164932.webp
│   │           ├── P173619.webp
│   │           ├── P173622.webp
│   │           ├── P173652.webp
│   │           ├── P173726.webp
│   │           ├── P174502.webp
│   │           ├── P188306.webp
│   │           ├── P188307.webp
│   │           ├── P188309.webp
│   │           ├── P196524.webp
│   │           ├── P196542.webp
│   │           ├── P201439.webp
│   │           ├── P201440.webp
│   │           ├── P203616.webp
│   │           ├── P2043.webp
│   │           ├── P2046.webp
│   │           ├── P205614.webp
│   │           ├── P214002.webp
│   │           ├── P217513.webp
│   │           ├── P217931.webp
│   │           ├── P217932.webp
│   │           ├── P218700.webp
│   │           ├── P230538.webp
│   │           ├── P232327.webp
│   │           ├── P232902.webp
│   │           ├── P232903.webp
│   │           ├── P232907.webp
│   │           ├── P232910.webp
│   │           ├── P232915.webp
│   │           ├── P232920.webp
│   │           ├── P244701.webp
│   │           ├── P248404.webp
│   │           ├── P248407.webp
│   │           ├── P251529.webp
│   │           ├── P254720.webp
│   │           ├── P257537.webp
│   │           ├── P266126.webp
│   │           ├── P268700.webp
│   │           ├── P269122.webp
│   │           ├── P270543.webp
│   │           ├── P270544.webp
│   │           ├── P270594.webp
│   │           ├── P271682.webp
│   │           ├── P278317.webp
│   │           ├── P281835.webp
│   │           ├── P282920.webp
│   │           ├── P282935.webp
│   │           ├── P283106.webp
│   │           ├── P283501.webp
│   │           ├── P294018.webp
│   │           ├── P296413.webp
│   │           ├── P296415.webp
│   │           ├── P297516.webp
│   │           ├── P297517.webp
│   │           ├── P297524.webp
│   │           ├── P297531.webp
│   │           ├── P297551.webp
│   │           ├── P302103.webp
│   │           ├── P302900.webp
│   │           ├── P306941.webp
│   │           ├── P309306.webp
│   │           ├── P309308.webp
│   │           ├── P309310.webp
│   │           ├── P309409.webp
│   │           ├── P311143.webp
│   │           ├── P34402.webp
│   │           ├── P3550.webp
│   │           ├── P3617.webp
│   │           ├── P374115.webp
│   │           ├── P374841.webp
│   │           ├── P375354.webp
│   │           ├── P375534.webp
│   │           ├── P375841.webp
│   │           ├── P375849.webp
│   │           ├── P375850.webp
│   │           ├── P375852.webp
│   │           ├── P375853.webp
│   │           ├── P375854.webp
│   │           ├── P375864.webp
│   │           ├── P376135.webp
│   │           ├── P376726.webp
│   │           ├── P377178.webp
│   │           ├── P377368.webp
│   │           ├── P377533.webp
│   │           ├── P377545.webp
│   │           ├── P377561.webp
│   │           ├── P377570.webp
│   │           ├── P377576.webp
│   │           ├── P377577.webp
│   │           ├── P377919.webp
│   │           ├── P378219.webp
│   │           ├── P378852.webp
│   │           ├── P379009.webp
│   │           ├── P379064.webp
│   │           ├── P379510.webp
│   │           ├── P379704.webp
│   │           ├── P379705.webp
│   │           ├── P379707.webp
│   │           ├── P379709.webp
│   │           ├── P379710.webp
│   │           ├── P379711.webp
│   │           ├── P379907.webp
│   │           ├── P379995.webp
│   │           ├── P380000.webp
│   │           ├── P380027.webp
│   │           ├── P380030.webp
│   │           ├── P381020.webp
│   │           ├── P381030.webp
│   │           ├── P38217.webp
│   │           ├── P382204.webp
│   │           ├── P382356.webp
│   │           ├── P383051.webp
│   │           ├── P383052.webp
│   │           ├── P383053.webp
│   │           ├── P383054.webp
│   │           ├── P383308.webp
│   │           ├── P384537.webp
│   │           ├── P384539.webp
│   │           ├── P384778.webp
│   │           ├── P384780.webp
│   │           ├── P384821.webp
│   │           ├── P385253.webp
│   │           ├── P385262.webp
│   │           ├── P385320.webp
│   │           ├── P385432.webp
│   │           ├── P385631.webp
│   │           ├── P385632.webp
│   │           ├── P385773.webp
│   │           ├── P386197.webp
│   │           ├── P386739.webp
│   │           ├── P386754.webp
│   │           ├── P386755.webp
│   │           ├── P386757.webp
│   │           ├── P386759.webp
│   │           ├── P386760.webp
│   │           ├── P386762.webp
│   │           ├── P386764.webp
│   │           ├── P387261.webp
│   │           ├── P387511.webp
│   │           ├── P388200.webp
│   │           ├── P388262.webp
│   │           ├── P388545.webp
│   │           ├── P388982.webp
│   │           ├── P391799.webp
│   │           ├── P391802.webp
│   │           ├── P392004.webp
│   │           ├── P392142.webp
│   │           ├── P392143.webp
│   │           ├── P392144.webp
│   │           ├── P392235.webp
│   │           ├── P392239.webp
│   │           ├── P392245.webp
│   │           ├── P392246.webp
│   │           ├── P392248.webp
│   │           ├── P392249.webp
│   │           ├── P392472.webp
│   │           ├── P392522.webp
│   │           ├── P392607.webp
│   │           ├── P392608.webp
│   │           ├── P392648.webp
│   │           ├── P39274.webp
│   │           ├── P392892.webp
│   │           ├── P393076.webp
│   │           ├── P393501.webp
│   │           ├── P393718.webp
│   │           ├── P394124.webp
│   │           ├── P394397.webp
│   │           ├── P394624.webp
│   │           ├── P394639.webp
│   │           ├── P394702.webp
│   │           ├── P394826.webp
│   │           ├── P395389.webp
│   │           ├── P395417.webp
│   │           ├── P395615.webp
│   │           ├── P395723.webp
│   │           ├── P396623.webp
│   │           ├── P397310.webp
│   │           ├── P397465.webp
│   │           ├── P397622.webp
│   │           ├── P397623.webp
│   │           ├── P397624.webp
│   │           ├── P397625.webp
│   │           ├── P397626.webp
│   │           ├── P397627.webp
│   │           ├── P397890.webp
│   │           ├── P398500.webp
│   │           ├── P398502.webp
│   │           ├── P398717.webp
│   │           ├── P398761.webp
│   │           ├── P399622.webp
│   │           ├── P399623.webp
│   │           ├── P399656.webp
│   │           ├── P39970.webp
│   │           ├── P399755.webp
│   │           ├── P399932.webp
│   │           ├── P399934.webp
│   │           ├── P400204.webp
│   │           ├── P400205.webp
│   │           ├── P400207.webp
│   │           ├── P400259.webp
│   │           ├── P4010.webp
│   │           ├── P401158.webp
│   │           ├── P4015.webp
│   │           ├── P401570.webp
│   │           ├── P4016.webp
│   │           ├── P402014.webp
│   │           ├── P402718.webp
│   │           ├── P402942.webp
│   │           ├── P402943.webp
│   │           ├── P402944.webp
│   │           ├── P402992.webp
│   │           ├── P4032.webp
│   │           ├── P403315.webp
│   │           ├── P403748.webp
│   │           ├── P403817.webp
│   │           ├── P403818.webp
│   │           ├── P4039.webp
│   │           ├── P404168.webp
│   │           ├── P404169.webp
│   │           ├── P404232.webp
│   │           ├── P404322.webp
│   │           ├── P404338.webp
│   │           ├── P404465.webp
│   │           ├── P404793.webp
│   │           ├── P404794.webp
│   │           ├── P404795.webp
│   │           ├── P405096.webp
│   │           ├── P405286.webp
│   │           ├── P405584.webp
│   │           ├── P405599.webp
│   │           ├── P405826.webp
│   │           ├── P405827.webp
│   │           ├── P405944.webp
│   │           ├── P406104.webp
│   │           ├── P406529.webp
│   │           ├── P406712.webp
│   │           ├── P406941.webp
│   │           ├── P406942.webp
│   │           ├── P407040.webp
│   │           ├── P407381.webp
│   │           ├── P407387.webp
│   │           ├── P407444.webp
│   │           ├── P407448.webp
│   │           ├── P407450.webp
│   │           ├── P408230.webp
│   │           ├── P408241.webp
│   │           ├── P408273.webp
│   │           ├── P408301.webp
│   │           ├── P408542.webp
│   │           ├── P408678.webp
│   │           ├── P409630.webp
│   │           ├── P409631.webp
│   │           ├── P409800.webp
│   │           ├── P409816.webp
│   │           ├── P409834.webp
│   │           ├── P409920.webp
│   │           ├── P410101.webp
│   │           ├── P410400.webp
│   │           ├── P410755.webp
│   │           ├── P410756.webp
│   │           ├── P410809.webp
│   │           ├── P410883.webp
│   │           ├── P411254.webp
│   │           ├── P411360.webp
│   │           ├── P411365.webp
│   │           ├── P411387.webp
│   │           ├── P411388.webp
│   │           ├── P411393.webp
│   │           ├── P411401.webp
│   │           ├── P411403.webp
│   │           ├── P411539.webp
│   │           ├── P411540.webp
│   │           ├── P411881.webp
│   │           ├── P412025.webp
│   │           ├── P412117.webp
│   │           ├── P412407.webp
│   │           ├── P413326.webp
│   │           ├── P413613.webp
│   │           ├── P414293.webp
│   │           ├── P414737.webp
│   │           ├── P415202.webp
│   │           ├── P415237.webp
│   │           ├── P415619.webp
│   │           ├── P415620.webp
│   │           ├── P415667.webp
│   │           ├── P415701.webp
│   │           ├── P415747.webp
│   │           ├── P415771.webp
│   │           ├── P415773.webp
│   │           ├── P415777.webp
│   │           ├── P416139.webp
│   │           ├── P416312.webp
│   │           ├── P416341.webp
│   │           ├── P416344.webp
│   │           ├── P416538.webp
│   │           ├── P416552.webp
│   │           ├── P416560.webp
│   │           ├── P416561.webp
│   │           ├── P416562.webp
│   │           ├── P416563.webp
│   │           ├── P416564.webp
│   │           ├── P416725.webp
│   │           ├── P416728.webp
│   │           ├── P416815.webp
│   │           ├── P416816.webp
│   │           ├── P416824.webp
│   │           ├── P416825.webp
│   │           ├── P416923.webp
│   │           ├── P417107.webp
│   │           ├── P417111.webp
│   │           ├── P417114.webp
│   │           ├── P417115.webp
│   │           ├── P417118.webp
│   │           ├── P417238.webp
│   │           ├── P417241.webp
│   │           ├── P417242.webp
│   │           ├── P417243.webp
│   │           ├── P417323.webp
│   │           ├── P417604.webp
│   │           ├── P417625.webp
│   │           ├── P417867.webp
│   │           ├── P417936.webp
│   │           ├── P417980.webp
│   │           ├── P417984.webp
│   │           ├── P418218.webp
│   │           ├── P418221.webp
│   │           ├── P418346.webp
│   │           ├── P418624.webp
│   │           ├── P418629.webp
│   │           ├── P418872.webp
│   │           ├── P419221.webp
│   │           ├── P419222.webp
│   │           ├── P419223.webp
│   │           ├── P419466.webp
│   │           ├── P419633.webp
│   │           ├── P420143.webp
│   │           ├── P420158.webp
│   │           ├── P420224.webp
│   │           ├── P420230.webp
│   │           ├── P420638.webp
│   │           ├── P420652.webp
│   │           ├── P420699.webp
│   │           ├── P421235.webp
│   │           ├── P421243.webp
│   │           ├── P421249.webp
│   │           ├── P421271.webp
│   │           ├── P421275.webp
│   │           ├── P421276.webp
│   │           ├── P421277.webp
│   │           ├── P421432.webp
│   │           ├── P421600.webp
│   │           ├── P421996.webp
│   │           ├── P421997.webp
│   │           ├── P421998.webp
│   │           ├── P422000.webp
│   │           ├── P422002.webp
│   │           ├── P422003.webp
│   │           ├── P422004.webp
│   │           ├── P422005.webp
│   │           ├── P422007.webp
│   │           ├── P422011.webp
│   │           ├── P422012.webp
│   │           ├── P422013.webp
│   │           ├── P422022.webp
│   │           ├── P42204.webp
│   │           ├── P42205.webp
│   │           ├── P422248.webp
│   │           ├── P422253.webp
│   │           ├── P422257.webp
│   │           ├── P422428.webp
│   │           ├── P422430.webp
│   │           ├── P422510.webp
│   │           ├── P422536.webp
│   │           ├── P422648.webp
│   │           ├── P422649.webp
│   │           ├── P422848.webp
│   │           ├── P422905.webp
│   │           ├── P423125.webp
│   │           ├── P423127.webp
│   │           ├── P423130.webp
│   │           ├── P423134.webp
│   │           ├── P423135.webp
│   │           ├── P423136.webp
│   │           ├── P423142.webp
│   │           ├── P423143.webp
│   │           ├── P423148.webp
│   │           ├── P423150.webp
│   │           ├── P423157.webp
│   │           ├── P423164.webp
│   │           ├── P423165.webp
│   │           ├── P423254.webp
│   │           ├── P423259.webp
│   │           ├── P423264.webp
│   │           ├── P423688.webp
│   │           ├── P423690.webp
│   │           ├── P424378.webp
│   │           ├── P424948.webp
│   │           ├── P424984.webp
│   │           ├── P424985.webp
│   │           ├── P424986.webp
│   │           ├── P424987.webp
│   │           ├── P424988.webp
│   │           ├── P424989.webp
│   │           ├── P424990.webp
│   │           ├── P426080.webp
│   │           ├── P426183.webp
│   │           ├── P426340.webp
│   │           ├── P426501.webp
│   │           ├── P426707.webp
│   │           ├── P426829.webp
│   │           ├── P426836.webp
│   │           ├── P427393.webp
│   │           ├── P427397.webp
│   │           ├── P427404.webp
│   │           ├── P427405.webp
│   │           ├── P427406.webp
│   │           ├── P427409.webp
│   │           ├── P427410.webp
│   │           ├── P427411.webp
│   │           ├── P427412.webp
│   │           ├── P427413.webp
│   │           ├── P427414.webp
│   │           ├── P427415.webp
│   │           ├── P427416.webp
│   │           ├── P427417.webp
│   │           ├── P427418.webp
│   │           ├── P427419.webp
│   │           ├── P427420.webp
│   │           ├── P427421.webp
│   │           ├── P427529.webp
│   │           ├── P427536.webp
│   │           ├── P427638.webp
│   │           ├── P427641.webp
│   │           ├── P427729.webp
│   │           ├── P427732.webp
│   │           ├── P428095.webp
│   │           ├── P428100.webp
│   │           ├── P428240.webp
│   │           ├── P428250.webp
│   │           ├── P428255.webp
│   │           ├── P428416.webp
│   │           ├── P428423.webp
│   │           ├── P428668.webp
│   │           ├── P428816.webp
│   │           ├── P428819.webp
│   │           ├── P429043.webp
│   │           ├── P429242.webp
│   │           ├── P429250.webp
│   │           ├── P429508.webp
│   │           ├── P429515.webp
│   │           ├── P429516.webp
│   │           ├── P429522.webp
│   │           ├── P429526.webp
│   │           ├── P429529.webp
│   │           ├── P429637.webp
│   │           ├── P429659.webp
│   │           ├── P429661.webp
│   │           ├── P429662.webp
│   │           ├── P429676.webp
│   │           ├── P429683.webp
│   │           ├── P429952.webp
│   │           ├── P429953.webp
│   │           ├── P429954.webp
│   │           ├── P430146.webp
│   │           ├── P430337.webp
│   │           ├── P430338.webp
│   │           ├── P430812.webp
│   │           ├── P430813.webp
│   │           ├── P430903.webp
│   │           ├── P431180.webp
│   │           ├── P431181.webp
│   │           ├── P431187.webp
│   │           ├── P431416.webp
│   │           ├── P431733.webp
│   │           ├── P431840.webp
│   │           ├── P431847.webp
│   │           ├── P431848.webp
│   │           ├── P432045.webp
│   │           ├── P432048.webp
│   │           ├── P432049.webp
│   │           ├── P432053.webp
│   │           ├── P432239.webp
│   │           ├── P432241.webp
│   │           ├── P432242.webp
│   │           ├── P432243.webp
│   │           ├── P432256.webp
│   │           ├── P432262.webp
│   │           ├── P432421.webp
│   │           ├── P432662.webp
│   │           ├── P432668.webp
│   │           ├── P432818.webp
│   │           ├── P432823.webp
│   │           ├── P432824.webp
│   │           ├── P432829.webp
│   │           ├── P432831.webp
│   │           ├── P433143.webp
│   │           ├── P433155.webp
│   │           ├── P433435.webp
│   │           ├── P433440.webp
│   │           ├── P433443.webp
│   │           ├── P433444.webp
│   │           ├── P433446.webp
│   │           ├── P433453.webp
│   │           ├── P433456.webp
│   │           ├── P433457.webp
│   │           ├── P433461.webp
│   │           ├── P433468.webp
│   │           ├── P433469.webp
│   │           ├── P433519.webp
│   │           ├── P433520.webp
│   │           ├── P433521.webp
│   │           ├── P433522.webp
│   │           ├── P433524.webp
│   │           ├── P433617.webp
│   │           ├── P433618.webp
│   │           ├── P433620.webp
│   │           ├── P433621.webp
│   │           ├── P433627.webp
│   │           ├── P433884.webp
│   │           ├── P433887.webp
│   │           ├── P433962.webp
│   │           ├── P433971.webp
│   │           ├── P433973.webp
│   │           ├── P433974.webp
│   │           ├── P433975.webp
│   │           ├── P434336.webp
│   │           ├── P434340.webp
│   │           ├── P434360.webp
│   │           ├── P434361.webp
│   │           ├── P434545.webp
│   │           ├── P434546.webp
│   │           ├── P434548.webp
│   │           ├── P434550.webp
│   │           ├── P435209.webp
│   │           ├── P435386.webp
│   │           ├── P435800.webp
│   │           ├── P435801.webp
│   │           ├── P435975.webp
│   │           ├── P436094.webp
│   │           ├── P436353.webp
│   │           ├── P436359.webp
│   │           ├── P436365.webp
│   │           ├── P436378.webp
│   │           ├── P436387.webp
│   │           ├── P436891.webp
│   │           ├── P437477.webp
│   │           ├── P437960.webp
│   │           ├── P437981.webp
│   │           ├── P438617.webp
│   │           ├── P438618.webp
│   │           ├── P438619.webp
│   │           ├── P438620.webp
│   │           ├── P438628.webp
│   │           ├── P438629.webp
│   │           ├── P438635.webp
│   │           ├── P438637.webp
│   │           ├── P438643.webp
│   │           ├── P438648.webp
│   │           ├── P439055.webp
│   │           ├── P439057.webp
│   │           ├── P439058.webp
│   │           ├── P439061.webp
│   │           ├── P439626.webp
│   │           ├── P439643.webp
│   │           ├── P439648.webp
│   │           ├── P439672.webp
│   │           ├── P439926.webp
│   │           ├── P439927.webp
│   │           ├── P439928.webp
│   │           ├── P440072.webp
│   │           ├── P440075.webp
│   │           ├── P440302.webp
│   │           ├── P440305.webp
│   │           ├── P440306.webp
│   │           ├── P440307.webp
│   │           ├── P440309.webp
│   │           ├── P440312.webp
│   │           ├── P440317.webp
│   │           ├── P440482.webp
│   │           ├── P440483.webp
│   │           ├── P440484.webp
│   │           ├── P440485.webp
│   │           ├── P440486.webp
│   │           ├── P440489.webp
│   │           ├── P440490.webp
│   │           ├── P440491.webp
│   │           ├── P440492.webp
│   │           ├── P440493.webp
│   │           ├── P440494.webp
│   │           ├── P440496.webp
│   │           ├── P440498.webp
│   │           ├── P440499.webp
│   │           ├── P440501.webp
│   │           ├── P440502.webp
│   │           ├── P440503.webp
│   │           ├── P440504.webp
│   │           ├── P440505.webp
│   │           ├── P440650.webp
│   │           ├── P440651.webp
│   │           ├── P440658.webp
│   │           ├── P440923.webp
│   │           ├── P440925.webp
│   │           ├── P440926.webp
│   │           ├── P440929.webp
│   │           ├── P440933.webp
│   │           ├── P440934.webp
│   │           ├── P440937.webp
│   │           ├── P440949.webp
│   │           ├── P440981.webp
│   │           ├── P441045.webp
│   │           ├── P441101.webp
│   │           ├── P441220.webp
│   │           ├── P441323.webp
│   │           ├── P441644.webp
│   │           ├── P441645.webp
│   │           ├── P442001.webp
│   │           ├── P442003.webp
│   │           ├── P442263.webp
│   │           ├── P442267.webp
│   │           ├── P442535.webp
│   │           ├── P442539.webp
│   │           ├── P442540.webp
│   │           ├── P442545.webp
│   │           ├── P442546.webp
│   │           ├── P442548.webp
│   │           ├── P442563.webp
│   │           ├── P442564.webp
│   │           ├── P442566.webp
│   │           ├── P442589.webp
│   │           ├── P442594.webp
│   │           ├── P442713.webp
│   │           ├── P442734.webp
│   │           ├── P442741.webp
│   │           ├── P442742.webp
│   │           ├── P442743.webp
│   │           ├── P442744.webp
│   │           ├── P442745.webp
│   │           ├── P442747.webp
│   │           ├── P442748.webp
│   │           ├── P442752.webp
│   │           ├── P442753.webp
│   │           ├── P442754.webp
│   │           ├── P442755.webp
│   │           ├── P442756.webp
│   │           ├── P442757.webp
│   │           ├── P442758.webp
│   │           ├── P442759.webp
│   │           ├── P442761.webp
│   │           ├── P442830.webp
│   │           ├── P442833.webp
│   │           ├── P442836.webp
│   │           ├── P442837.webp
│   │           ├── P442838.webp
│   │           ├── P442839.webp
│   │           ├── P442840.webp
│   │           ├── P442841.webp
│   │           ├── P442843.webp
│   │           ├── P442850.webp
│   │           ├── P442853.webp
│   │           ├── P442854.webp
│   │           ├── P442857.webp
│   │           ├── P442858.webp
│   │           ├── P442859.webp
│   │           ├── P442860.webp
│   │           ├── P442867.webp
│   │           ├── P442871.webp
│   │           ├── P442989.webp
│   │           ├── P442990.webp
│   │           ├── P443349.webp
│   │           ├── P443350.webp
│   │           ├── P443351.webp
│   │           ├── P443352.webp
│   │           ├── P443358.webp
│   │           ├── P443359.webp
│   │           ├── P443366.webp
│   │           ├── P443369.webp
│   │           ├── P443370.webp
│   │           ├── P443375.webp
│   │           ├── P443376.webp
│   │           ├── P443383.webp
│   │           ├── P443549.webp
│   │           ├── P443550.webp
│   │           ├── P443563.webp
│   │           ├── P443700.webp
│   │           ├── P443829.webp
│   │           ├── P443830.webp
│   │           ├── P443833.webp
│   │           ├── P443834.webp
│   │           ├── P443837.webp
│   │           ├── P443838.webp
│   │           ├── P443839.webp
│   │           ├── P443840.webp
│   │           ├── P443841.webp
│   │           ├── P443842.webp
│   │           ├── P443843.webp
│   │           ├── P443845.webp
│   │           ├── P443846.webp
│   │           ├── P444013.webp
│   │           ├── P444057.webp
│   │           ├── P444216.webp
│   │           ├── P444222.webp
│   │           ├── P444225.webp
│   │           ├── P444226.webp
│   │           ├── P444614.webp
│   │           ├── P444718.webp
│   │           ├── P444964.webp
│   │           ├── P444967.webp
│   │           ├── P444968.webp
│   │           ├── P444969.webp
│   │           ├── P444970.webp
│   │           ├── P444980.webp
│   │           ├── P445726.webp
│   │           ├── P445827.webp
│   │           ├── P445832.webp
│   │           ├── P445833.webp
│   │           ├── P445951.webp
│   │           ├── P446419.webp
│   │           ├── P446421.webp
│   │           ├── P446422.webp
│   │           ├── P446423.webp
│   │           ├── P446612.webp
│   │           ├── P446629.webp
│   │           ├── P446630.webp
│   │           ├── P446638.webp
│   │           ├── P446641.webp
│   │           ├── P446822.webp
│   │           ├── P446908.webp
│   │           ├── P446909.webp
│   │           ├── P446916.webp
│   │           ├── P446930.webp
│   │           ├── P446934.webp
│   │           ├── P446938.webp
│   │           ├── P446942.webp
│   │           ├── P447199.webp
│   │           ├── P447200.webp
│   │           ├── P447210.webp
│   │           ├── P447212.webp
│   │           ├── P447213.webp
│   │           ├── P447409.webp
│   │           ├── P447504.webp
│   │           ├── P447592.webp
│   │           ├── P447596.webp
│   │           ├── P447597.webp
│   │           ├── P447603.webp
│   │           ├── P447607.webp
│   │           ├── P447608.webp
│   │           ├── P447773.webp
│   │           ├── P447778.webp
│   │           ├── P447780.webp
│   │           ├── P447781.webp
│   │           ├── P447782.webp
│   │           ├── P447783.webp
│   │           ├── P447785.webp
│   │           ├── P447787.webp
│   │           ├── P447788.webp
│   │           ├── P447789.webp
│   │           ├── P447790.webp
│   │           ├── P447791.webp
│   │           ├── P448181.webp
│   │           ├── P448184.webp
│   │           ├── P448185.webp
│   │           ├── P448192.webp
│   │           ├── P448200.webp
│   │           ├── P448201.webp
│   │           ├── P448202.webp
│   │           ├── P448203.webp
│   │           ├── P448207.webp
│   │           ├── P448530.webp
│   │           ├── P448537.webp
│   │           ├── P448553.webp
│   │           ├── P448554.webp
│   │           ├── P448557.webp
│   │           ├── P448562.webp
│   │           ├── P448563.webp
│   │           ├── P448710.webp
│   │           ├── P448711.webp
│   │           ├── P448715.webp
│   │           ├── P448719.webp
│   │           ├── P448802.webp
│   │           ├── P448852.webp
│   │           ├── P448853.webp
│   │           ├── P448932.webp
│   │           ├── P448934.webp
│   │           ├── P448937.webp
│   │           ├── P449102.webp
│   │           ├── P449150.webp
│   │           ├── P449156.webp
│   │           ├── P449158.webp
│   │           ├── P449175.webp
│   │           ├── P449177.webp
│   │           ├── P449180.webp
│   │           ├── P449188.webp
│   │           ├── P449541.webp
│   │           ├── P449599.webp
│   │           ├── P449601.webp
│   │           ├── P449835.webp
│   │           ├── P449836.webp
│   │           ├── P450210.webp
│   │           ├── P450211.webp
│   │           ├── P450244.webp
│   │           ├── P450262.webp
│   │           ├── P450271.webp
│   │           ├── P450290.webp
│   │           ├── P450583.webp
│   │           ├── P450587.webp
│   │           ├── P450614.webp
│   │           ├── P450632.webp
│   │           ├── P450633.webp
│   │           ├── P450917.webp
│   │           ├── P450947.webp
│   │           ├── P451745.webp
│   │           ├── P451748.webp
│   │           ├── P452002.webp
│   │           ├── P452004.webp
│   │           ├── P453224.webp
│   │           ├── P453225.webp
│   │           ├── P453226.webp
│   │           ├── P453227.webp
│   │           ├── P453253.webp
│   │           ├── P453713.webp
│   │           ├── P453816.webp
│   │           ├── P453818.webp
│   │           ├── P453822.webp
│   │           ├── P453823.webp
│   │           ├── P453824.webp
│   │           ├── P453825.webp
│   │           ├── P453826.webp
│   │           ├── P453928.webp
│   │           ├── P453929.webp
│   │           ├── P453930.webp
│   │           ├── P454018.webp
│   │           ├── P454019.webp
│   │           ├── P454084.webp
│   │           ├── P454085.webp
│   │           ├── P454086.webp
│   │           ├── P454090.webp
│   │           ├── P454095.webp
│   │           ├── P454100.webp
│   │           ├── P454102.webp
│   │           ├── P454120.webp
│   │           ├── P454313.webp
│   │           ├── P454315.webp
│   │           ├── P454376.webp
│   │           ├── P454378.webp
│   │           ├── P454380.webp
│   │           ├── P454383.webp
│   │           ├── P454384.webp
│   │           ├── P454385.webp
│   │           ├── P454387.webp
│   │           ├── P454388.webp
│   │           ├── P454389.webp
│   │           ├── P454395.webp
│   │           ├── P454396.webp
│   │           ├── P454514.webp
│   │           ├── P454771.webp
│   │           ├── P454794.webp
│   │           ├── P454799.webp
│   │           ├── P454806.webp
│   │           ├── P454821.webp
│   │           ├── P454837.webp
│   │           ├── P454838.webp
│   │           ├── P454935.webp
│   │           ├── P454936.webp
│   │           ├── P454937.webp
│   │           ├── P455212.webp
│   │           ├── P455215.webp
│   │           ├── P455217.webp
│   │           ├── P455235.webp
│   │           ├── P455236.webp
│   │           ├── P455237.webp
│   │           ├── P455241.webp
│   │           ├── P455242.webp
│   │           ├── P455338.webp
│   │           ├── P455339.webp
│   │           ├── P455341.webp
│   │           ├── P455364.webp
│   │           ├── P455365.webp
│   │           ├── P455366.webp
│   │           ├── P455368.webp
│   │           ├── P455369.webp
│   │           ├── P455610.webp
│   │           ├── P455611.webp
│   │           ├── P455612.webp
│   │           ├── P455613.webp
│   │           ├── P455614.webp
│   │           ├── P455618.webp
│   │           ├── P455622.webp
│   │           ├── P455623.webp
│   │           ├── P455676.webp
│   │           ├── P455894.webp
│   │           ├── P455897.webp
│   │           ├── P455898.webp
│   │           ├── P455899.webp
│   │           ├── P455900.webp
│   │           ├── P455909.webp
│   │           ├── P455919.webp
│   │           ├── P455924.webp
│   │           ├── P455926.webp
│   │           ├── P455927.webp
│   │           ├── P455929.webp
│   │           ├── P455930.webp
│   │           ├── P455931.webp
│   │           ├── P455934.webp
│   │           ├── P455936.webp
│   │           ├── P456126.webp
│   │           ├── P456192.webp
│   │           ├── P456193.webp
│   │           ├── P456194.webp
│   │           ├── P456204.webp
│   │           ├── P456206.webp
│   │           ├── P456207.webp
│   │           ├── P456208.webp
│   │           ├── P456210.webp
│   │           ├── P456211.webp
│   │           ├── P456213.webp
│   │           ├── P456218.webp
│   │           ├── P456392.webp
│   │           ├── P456395.webp
│   │           ├── P456398.webp
│   │           ├── P456399.webp
│   │           ├── P456400.webp
│   │           ├── P456407.webp
│   │           ├── P456410.webp
│   │           ├── P456412.webp
│   │           ├── P456413.webp
│   │           ├── P456414.webp
│   │           ├── P456417.webp
│   │           ├── P456418.webp
│   │           ├── P456421.webp
│   │           ├── P456566.webp
│   │           ├── P456569.webp
│   │           ├── P456571.webp
│   │           ├── P456572.webp
│   │           ├── P456582.webp
│   │           ├── P456957.webp
│   │           ├── P456988.webp
│   │           ├── P456989.webp
│   │           ├── P456990.webp
│   │           ├── P456991.webp
│   │           ├── P456994.webp
│   │           ├── P456997.webp
│   │           ├── P457002.webp
│   │           ├── P457005.webp
│   │           ├── P457008.webp
│   │           ├── P457441.webp
│   │           ├── P457442.webp
│   │           ├── P457468.webp
│   │           ├── P457510.webp
│   │           ├── P457512.webp
│   │           ├── P457517.webp
│   │           ├── P457519.webp
│   │           ├── P457520.webp
│   │           ├── P457521.webp
│   │           ├── P457522.webp
│   │           ├── P457694.webp
│   │           ├── P457695.webp
│   │           ├── P457696.webp
│   │           ├── P457697.webp
│   │           ├── P457854.webp
│   │           ├── P457864.webp
│   │           ├── P458209.webp
│   │           ├── P458216.webp
│   │           ├── P458219.webp
│   │           ├── P458546.webp
│   │           ├── P458576.webp
│   │           ├── P458724.webp
│   │           ├── P458755.webp
│   │           ├── P458900.webp
│   │           ├── P458917.webp
│   │           ├── P458961.webp
│   │           ├── P458962.webp
│   │           ├── P459116.webp
│   │           ├── P459127.webp
│   │           ├── P459128.webp
│   │           ├── P459129.webp
│   │           ├── P459130.webp
│   │           ├── P459131.webp
│   │           ├── P459133.webp
│   │           ├── P459140.webp
│   │           ├── P459141.webp
│   │           ├── P459299.webp
│   │           ├── P459300.webp
│   │           ├── P459301.webp
│   │           ├── P459835.webp
│   │           ├── P460512.webp
│   │           ├── P460513.webp
│   │           ├── P460514.webp
│   │           ├── P460515.webp
│   │           ├── P460516.webp
│   │           ├── P460554.webp
│   │           ├── P460578.webp
│   │           ├── P460624.webp
│   │           ├── P460627.webp
│   │           ├── P460701.webp
│   │           ├── P460723.webp
│   │           ├── P460746.webp
│   │           ├── P460747.webp
│   │           ├── P460758.webp
│   │           ├── P460779.webp
│   │           ├── P460855.webp
│   │           ├── P460856.webp
│   │           ├── P461159.webp
│   │           ├── P461160.webp
│   │           ├── P461161.webp
│   │           ├── P461162.webp
│   │           ├── P461165.webp
│   │           ├── P461177.webp
│   │           ├── P461195.webp
│   │           ├── P461213.webp
│   │           ├── P461439.webp
│   │           ├── P461451.webp
│   │           ├── P461491.webp
│   │           ├── P461520.webp
│   │           ├── P461521.webp
│   │           ├── P461522.webp
│   │           ├── P461537.webp
│   │           ├── P461555.webp
│   │           ├── P461667.webp
│   │           ├── P461933.webp
│   │           ├── P461935.webp
│   │           ├── P461936.webp
│   │           ├── P461947.webp
│   │           ├── P461948.webp
│   │           ├── P461949.webp
│   │           ├── P461950.webp
│   │           ├── P462336.webp
│   │           ├── P462339.webp
│   │           ├── P462344.webp
│   │           ├── P462347.webp
│   │           ├── P462390.webp
│   │           ├── P462666.webp
│   │           ├── P462699.webp
│   │           ├── P462747.webp
│   │           ├── P462748.webp
│   │           ├── P462829.webp
│   │           ├── P462891.webp
│   │           ├── P463036.webp
│   │           ├── P463105.webp
│   │           ├── P463109.webp
│   │           ├── P463144.webp
│   │           ├── P463353.webp
│   │           ├── P463371.webp
│   │           ├── P463613.webp
│   │           ├── P463665.webp
│   │           ├── P463964.webp
│   │           ├── P464233.webp
│   │           ├── P464234.webp
│   │           ├── P464235.webp
│   │           ├── P464237.webp
│   │           ├── P464239.webp
│   │           ├── P464240.webp
│   │           ├── P464242.webp
│   │           ├── P464243.webp
│   │           ├── P464244.webp
│   │           ├── P464245.webp
│   │           ├── P464250.webp
│   │           ├── P464288.webp
│   │           ├── P465365.webp
│   │           ├── P465368.webp
│   │           ├── P465741.webp
│   │           ├── P465752.webp
│   │           ├── P465803.webp
│   │           ├── P465808.webp
│   │           ├── P466114.webp
│   │           ├── P466117.webp
│   │           ├── P466122.webp
│   │           ├── P466123.webp
│   │           ├── P466134.webp
│   │           ├── P466142.webp
│   │           ├── P466153.webp
│   │           ├── P466154.webp
│   │           ├── P466155.webp
│   │           ├── P466163.webp
│   │           ├── P466164.webp
│   │           ├── P466661.webp
│   │           ├── P466673.webp
│   │           ├── P467028.webp
│   │           ├── P467038.webp
│   │           ├── P467110.webp
│   │           ├── P467111.webp
│   │           ├── P467115.webp
│   │           ├── P467118.webp
│   │           ├── P467120.webp
│   │           ├── P467122.webp
│   │           ├── P467123.webp
│   │           ├── P467124.webp
│   │           ├── P467126.webp
│   │           ├── P467137.webp
│   │           ├── P467247.webp
│   │           ├── P467248.webp
│   │           ├── P467250.webp
│   │           ├── P467251.webp
│   │           ├── P467602.webp
│   │           ├── P467614.webp
│   │           ├── P467615.webp
│   │           ├── P467617.webp
│   │           ├── P467630.webp
│   │           ├── P467647.webp
│   │           ├── P467650.webp
│   │           ├── P467651.webp
│   │           ├── P467652.webp
│   │           ├── P467655.webp
│   │           ├── P467748.webp
│   │           ├── P467749.webp
│   │           ├── P467750.webp
│   │           ├── P467762.webp
│   │           ├── P467945.webp
│   │           ├── P467969.webp
│   │           ├── P467970.webp
│   │           ├── P467971.webp
│   │           ├── P467972.webp
│   │           ├── P467973.webp
│   │           ├── P467976.webp
│   │           ├── P468143.webp
│   │           ├── P468149.webp
│   │           ├── P468211.webp
│   │           ├── P468229.webp
│   │           ├── P468351.webp
│   │           ├── P468369.webp
│   │           ├── P468396.webp
│   │           ├── P468408.webp
│   │           ├── P468409.webp
│   │           ├── P468411.webp
│   │           ├── P468412.webp
│   │           ├── P468637.webp
│   │           ├── P468640.webp
│   │           ├── P468652.webp
│   │           ├── P468658.webp
│   │           ├── P468671.webp
│   │           ├── P468672.webp
│   │           ├── P468684.webp
│   │           ├── P468709.webp
│   │           ├── P468813.webp
│   │           ├── P468818.webp
│   │           ├── P468821.webp
│   │           ├── P468850.webp
│   │           ├── P469085.webp
│   │           ├── P469086.webp
│   │           ├── P469087.webp
│   │           ├── P469088.webp
│   │           ├── P469110.webp
│   │           ├── P469111.webp
│   │           ├── P469112.webp
│   │           ├── P469118.webp
│   │           ├── P469196.webp
│   │           ├── P469200.webp
│   │           ├── P469213.webp
│   │           ├── P469439.webp
│   │           ├── P469444.webp
│   │           ├── P469448.webp
│   │           ├── P469449.webp
│   │           ├── P469451.webp
│   │           ├── P469454.webp
│   │           ├── P469478.webp
│   │           ├── P469482.webp
│   │           ├── P469490.webp
│   │           ├── P469502.webp
│   │           ├── P469503.webp
│   │           ├── P469504.webp
│   │           ├── P469505.webp
│   │           ├── P469506.webp
│   │           ├── P469507.webp
│   │           ├── P469508.webp
│   │           ├── P469510.webp
│   │           ├── P469511.webp
│   │           ├── P469512.webp
│   │           ├── P469513.webp
│   │           ├── P469514.webp
│   │           ├── P469515.webp
│   │           ├── P469516.webp
│   │           ├── P469517.webp
│   │           ├── P469518.webp
│   │           ├── P469519.webp
│   │           ├── P469520.webp
│   │           ├── P469522.webp
│   │           ├── P469523.webp
│   │           ├── P469524.webp
│   │           ├── P469525.webp
│   │           ├── P469526.webp
│   │           ├── P469527.webp
│   │           ├── P469528.webp
│   │           ├── P469530.webp
│   │           ├── P469537.webp
│   │           ├── P469538.webp
│   │           ├── P469544.webp
│   │           ├── P469818.webp
│   │           ├── P469830.webp
│   │           ├── P469862.webp
│   │           ├── P470007.webp
│   │           ├── P470024.webp
│   │           ├── P470040.webp
│   │           ├── P470041.webp
│   │           ├── P470048.webp
│   │           ├── P470049.webp
│   │           ├── P470057.webp
│   │           ├── P470058.webp
│   │           ├── P470065.webp
│   │           ├── P470221.webp
│   │           ├── P470227.webp
│   │           ├── P470240.webp
│   │           ├── P470243.webp
│   │           ├── P470245.webp
│   │           ├── P470246.webp
│   │           ├── P470247.webp
│   │           ├── P470248.webp
│   │           ├── P470255.webp
│   │           ├── P470259.webp
│   │           ├── P470506.webp
│   │           ├── P470507.webp
│   │           ├── P470508.webp
│   │           ├── P470509.webp
│   │           ├── P470510.webp
│   │           ├── P470529.webp
│   │           ├── P470535.webp
│   │           ├── P470536.webp
│   │           ├── P471000.webp
│   │           ├── P471003.webp
│   │           ├── P471009.webp
│   │           ├── P471025.webp
│   │           ├── P471029.webp
│   │           ├── P471033.webp
│   │           ├── P471037.webp
│   │           ├── P471038.webp
│   │           ├── P471039.webp
│   │           ├── P471040.webp
│   │           ├── P471041.webp
│   │           ├── P471042.webp
│   │           ├── P471043.webp
│   │           ├── P471045.webp
│   │           ├── P471046.webp
│   │           ├── P471062.webp
│   │           ├── P471064.webp
│   │           ├── P471065.webp
│   │           ├── P471085.webp
│   │           ├── P471086.webp
│   │           ├── P471097.webp
│   │           ├── P471101.webp
│   │           ├── P471111.webp
│   │           ├── P471226.webp
│   │           ├── P471227.webp
│   │           ├── P471237.webp
│   │           ├── P471535.webp
│   │           ├── P471541.webp
│   │           ├── P471546.webp
│   │           ├── P471547.webp
│   │           ├── P471566.webp
│   │           ├── P471567.webp
│   │           ├── P471761.webp
│   │           ├── P471788.webp
│   │           ├── P471793.webp
│   │           ├── P472021.webp
│   │           ├── P472024.webp
│   │           ├── P472025.webp
│   │           ├── P472028.webp
│   │           ├── P472050.webp
│   │           ├── P472052.webp
│   │           ├── P472057.webp
│   │           ├── P472302.webp
│   │           ├── P472311.webp
│   │           ├── P472341.webp
│   │           ├── P472343.webp
│   │           ├── P472448.webp
│   │           ├── P472451.webp
│   │           ├── P472453.webp
│   │           ├── P472454.webp
│   │           ├── P472455.webp
│   │           ├── P472466.webp
│   │           ├── P472467.webp
│   │           ├── P472468.webp
│   │           ├── P472469.webp
│   │           ├── P472472.webp
│   │           ├── P472810.webp
│   │           ├── P472981.webp
│   │           ├── P473126.webp
│   │           ├── P473133.webp
│   │           ├── P473148.webp
│   │           ├── P473160.webp
│   │           ├── P473172.webp
│   │           ├── P473267.webp
│   │           ├── P473268.webp
│   │           ├── P473304.webp
│   │           ├── P473322.webp
│   │           ├── P473336.webp
│   │           ├── P473723.webp
│   │           ├── P473724.webp
│   │           ├── P473725.webp
│   │           ├── P473726.webp
│   │           ├── P473729.webp
│   │           ├── P473820.webp
│   │           ├── P473828.webp
│   │           ├── P474060.webp
│   │           ├── P474068.webp
│   │           ├── P474075.webp
│   │           ├── P474078.webp
│   │           ├── P474079.webp
│   │           ├── P474107.webp
│   │           ├── P474109.webp
│   │           ├── P474110.webp
│   │           ├── P474111.webp
│   │           ├── P474113.webp
│   │           ├── P474114.webp
│   │           ├── P474115.webp
│   │           ├── P474116.webp
│   │           ├── P474117.webp
│   │           ├── P474118.webp
│   │           ├── P474121.webp
│   │           ├── P474122.webp
│   │           ├── P474125.webp
│   │           ├── P474304.webp
│   │           ├── P474325.webp
│   │           ├── P474326.webp
│   │           ├── P474329.webp
│   │           ├── P474330.webp
│   │           ├── P474332.webp
│   │           ├── P474333.webp
│   │           ├── P474340.webp
│   │           ├── P474371.webp
│   │           ├── P474376.webp
│   │           ├── P474377.webp
│   │           ├── P474809.webp
│   │           ├── P474822.webp
│   │           ├── P474823.webp
│   │           ├── P474824.webp
│   │           ├── P474825.webp
│   │           ├── P474826.webp
│   │           ├── P474832.webp
│   │           ├── P474838.webp
│   │           ├── P474839.webp
│   │           ├── P474840.webp
│   │           ├── P474843.webp
│   │           ├── P474844.webp
│   │           ├── P474936.webp
│   │           ├── P474937.webp
│   │           ├── P474938.webp
│   │           ├── P474939.webp
│   │           ├── P474940.webp
│   │           ├── P474953.webp
│   │           ├── P474956.webp
│   │           ├── P474957.webp
│   │           ├── P474967.webp
│   │           ├── P474968.webp
│   │           ├── P474970.webp
│   │           ├── P474971.webp
│   │           ├── P474972.webp
│   │           ├── P475084.webp
│   │           ├── P475086.webp
│   │           ├── P475112.webp
│   │           ├── P475124.webp
│   │           ├── P475135.webp
│   │           ├── P475143.webp
│   │           ├── P475159.webp
│   │           ├── P475172.webp
│   │           ├── P475180.webp
│   │           ├── P475181.webp
│   │           ├── P475182.webp
│   │           ├── P475183.webp
│   │           ├── P475184.webp
│   │           ├── P475185.webp
│   │           ├── P475186.webp
│   │           ├── P475187.webp
│   │           ├── P475188.webp
│   │           ├── P475189.webp
│   │           ├── P475190.webp
│   │           ├── P475192.webp
│   │           ├── P475193.webp
│   │           ├── P475194.webp
│   │           ├── P475195.webp
│   │           ├── P475196.webp
│   │           ├── P475197.webp
│   │           ├── P475200.webp
│   │           ├── P475201.webp
│   │           ├── P475203.webp
│   │           ├── P475204.webp
│   │           ├── P475540.webp
│   │           ├── P475543.webp
│   │           ├── P475589.webp
│   │           ├── P475590.webp
│   │           ├── P475629.webp
│   │           ├── P475630.webp
│   │           ├── P475906.webp
│   │           ├── P475907.webp
│   │           ├── P475908.webp
│   │           ├── P475921.webp
│   │           ├── P475932.webp
│   │           ├── P475951.webp
│   │           ├── P476009.webp
│   │           ├── P476010.webp
│   │           ├── P476028.webp
│   │           ├── P476414.webp
│   │           ├── P476415.webp
│   │           ├── P476428.webp
│   │           ├── P476436.webp
│   │           ├── P476447.webp
│   │           ├── P476459.webp
│   │           ├── P476485.webp
│   │           ├── P476513.webp
│   │           ├── P476538.webp
│   │           ├── P476540.webp
│   │           ├── P476553.webp
│   │           ├── P476554.webp
│   │           ├── P476674.webp
│   │           ├── P476675.webp
│   │           ├── P476676.webp
│   │           ├── P476677.webp
│   │           ├── P476678.webp
│   │           ├── P476679.webp
│   │           ├── P476680.webp
│   │           ├── P476683.webp
│   │           ├── P476726.webp
│   │           ├── P476729.webp
│   │           ├── P476730.webp
│   │           ├── P476731.webp
│   │           ├── P476733.webp
│   │           ├── P476736.webp
│   │           ├── P476843.webp
│   │           ├── P476876.webp
│   │           ├── P476893.webp
│   │           ├── P476894.webp
│   │           ├── P477157.webp
│   │           ├── P477202.webp
│   │           ├── P477413.webp
│   │           ├── P477492.webp
│   │           ├── P477830.webp
│   │           ├── P477961.webp
│   │           ├── P477985.webp
│   │           ├── P478020.webp
│   │           ├── P478021.webp
│   │           ├── P478029.webp
│   │           ├── P478030.webp
│   │           ├── P478239.webp
│   │           ├── P478274.webp
│   │           ├── P478731.webp
│   │           ├── P479125.webp
│   │           ├── P479304.webp
│   │           ├── P479313.webp
│   │           ├── P479318.webp
│   │           ├── P479319.webp
│   │           ├── P479327.webp
│   │           ├── P479329.webp
│   │           ├── P479330.webp
│   │           ├── P479339.webp
│   │           ├── P479340.webp
│   │           ├── P479348.webp
│   │           ├── P479351.webp
│   │           ├── P479352.webp
│   │           ├── P479353.webp
│   │           ├── P479354.webp
│   │           ├── P479362.webp
│   │           ├── P479632.webp
│   │           ├── P479633.webp
│   │           ├── P479645.webp
│   │           ├── P479692.webp
│   │           ├── P479701.webp
│   │           ├── P479703.webp
│   │           ├── P479705.webp
│   │           ├── P479706.webp
│   │           ├── P479722.webp
│   │           ├── P479732.webp
│   │           ├── P479734.webp
│   │           ├── P479839.webp
│   │           ├── P479840.webp
│   │           ├── P479841.webp
│   │           ├── P479860.webp
│   │           ├── P479903.webp
│   │           ├── P479904.webp
│   │           ├── P479971.webp
│   │           ├── P480160.webp
│   │           ├── P480162.webp
│   │           ├── P480165.webp
│   │           ├── P480177.webp
│   │           ├── P480191.webp
│   │           ├── P480192.webp
│   │           ├── P480274.webp
│   │           ├── P480278.webp
│   │           ├── P480280.webp
│   │           ├── P480284.webp
│   │           ├── P480285.webp
│   │           ├── P480300.webp
│   │           ├── P480301.webp
│   │           ├── P480444.webp
│   │           ├── P480447.webp
│   │           ├── P480461.webp
│   │           ├── P480600.webp
│   │           ├── P480603.webp
│   │           ├── P480606.webp
│   │           ├── P480607.webp
│   │           ├── P480612.webp
│   │           ├── P480613.webp
│   │           ├── P480628.webp
│   │           ├── P480629.webp
│   │           ├── P480630.webp
│   │           ├── P480986.webp
│   │           ├── P481058.webp
│   │           ├── P481060.webp
│   │           ├── P481084.webp
│   │           ├── P481086.webp
│   │           ├── P481096.webp
│   │           ├── P481142.webp
│   │           ├── P481145.webp
│   │           ├── P481161.webp
│   │           ├── P481162.webp
│   │           ├── P481164.webp
│   │           ├── P481169.webp
│   │           ├── P481335.webp
│   │           ├── P481336.webp
│   │           ├── P481340.webp
│   │           ├── P481341.webp
│   │           ├── P481348.webp
│   │           ├── P481354.webp
│   │           ├── P481363.webp
│   │           ├── P481366.webp
│   │           ├── P481367.webp
│   │           ├── P481371.webp
│   │           ├── P481390.webp
│   │           ├── P481401.webp
│   │           ├── P481408.webp
│   │           ├── P481697.webp
│   │           ├── P481699.webp
│   │           ├── P481700.webp
│   │           ├── P481701.webp
│   │           ├── P481703.webp
│   │           ├── P481710.webp
│   │           ├── P481732.webp
│   │           ├── P481739.webp
│   │           ├── P481742.webp
│   │           ├── P481743.webp
│   │           ├── P481748.webp
│   │           ├── P481817.webp
│   │           ├── P481825.webp
│   │           ├── P481828.webp
│   │           ├── P481830.webp
│   │           ├── P481831.webp
│   │           ├── P481832.webp
│   │           ├── P481833.webp
│   │           ├── P481834.webp
│   │           ├── P481972.webp
│   │           ├── P481973.webp
│   │           ├── P481989.webp
│   │           ├── P482005.webp
│   │           ├── P482006.webp
│   │           ├── P482007.webp
│   │           ├── P482008.webp
│   │           ├── P482024.webp
│   │           ├── P482025.webp
│   │           ├── P482061.webp
│   │           ├── P482068.webp
│   │           ├── P482074.webp
│   │           ├── P482260.webp
│   │           ├── P482264.webp
│   │           ├── P482269.webp
│   │           ├── P482298.webp
│   │           ├── P482320.webp
│   │           ├── P482321.webp
│   │           ├── P482322.webp
│   │           ├── P482323.webp
│   │           ├── P482325.webp
│   │           ├── P482327.webp
│   │           ├── P482328.webp
│   │           ├── P482329.webp
│   │           ├── P482510.webp
│   │           ├── P482529.webp
│   │           ├── P482535.webp
│   │           ├── P482540.webp
│   │           ├── P482551.webp
│   │           ├── P482552.webp
│   │           ├── P482675.webp
│   │           ├── P482676.webp
│   │           ├── P482681.webp
│   │           ├── P482692.webp
│   │           ├── P482693.webp
│   │           ├── P482694.webp
│   │           ├── P482695.webp
│   │           ├── P482696.webp
│   │           ├── P482698.webp
│   │           ├── P482739.webp
│   │           ├── P482740.webp
│   │           ├── P482741.webp
│   │           ├── P482742.webp
│   │           ├── P482753.webp
│   │           ├── P482754.webp
│   │           ├── P482755.webp
│   │           ├── P482757.webp
│   │           ├── P483060.webp
│   │           ├── P483076.webp
│   │           ├── P483090.webp
│   │           ├── P483127.webp
│   │           ├── P483128.webp
│   │           ├── P483136.webp
│   │           ├── P483137.webp
│   │           ├── P483138.webp
│   │           ├── P483146.webp
│   │           ├── P483151.webp
│   │           ├── P483453.webp
│   │           ├── P483455.webp
│   │           ├── P483457.webp
│   │           ├── P483496.webp
│   │           ├── P483643.webp
│   │           ├── P483658.webp
│   │           ├── P483661.webp
│   │           ├── P483664.webp
│   │           ├── P483679.webp
│   │           ├── P483692.webp
│   │           ├── P483696.webp
│   │           ├── P483697.webp
│   │           ├── P483698.webp
│   │           ├── P483699.webp
│   │           ├── P483700.webp
│   │           ├── P483701.webp
│   │           ├── P483708.webp
│   │           ├── P484033.webp
│   │           ├── P484055.webp
│   │           ├── P484067.webp
│   │           ├── P484080.webp
│   │           ├── P484081.webp
│   │           ├── P500002.webp
│   │           ├── P500019.webp
│   │           ├── P500039.webp
│   │           ├── P500055.webp
│   │           ├── P500094.webp
│   │           ├── P500096.webp
│   │           ├── P500098.webp
│   │           ├── P500101.webp
│   │           ├── P500102.webp
│   │           ├── P500109.webp
│   │           ├── P500111.webp
│   │           ├── P500112.webp
│   │           ├── P500113.webp
│   │           ├── P500114.webp
│   │           ├── P500117.webp
│   │           ├── P500121.webp
│   │           ├── P500138.webp
│   │           ├── P500160.webp
│   │           ├── P500240.webp
│   │           ├── P500244.webp
│   │           ├── P500245.webp
│   │           ├── P500288.webp
│   │           ├── P500307.webp
│   │           ├── P500318.webp
│   │           ├── P500329.webp
│   │           ├── P500399.webp
│   │           ├── P500420.webp
│   │           ├── P500428.webp
│   │           ├── P500445.webp
│   │           ├── P500471.webp
│   │           ├── P500472.webp
│   │           ├── P500613.webp
│   │           ├── P500614.webp
│   │           ├── P500618.webp
│   │           ├── P500626.webp
│   │           ├── P500633.webp
│   │           ├── P500687.webp
│   │           ├── P500696.webp
│   │           ├── P500701.webp
│   │           ├── P500705.webp
│   │           ├── P500716.webp
│   │           ├── P500718.webp
│   │           ├── P500744.webp
│   │           ├── P500746.webp
│   │           ├── P500753.webp
│   │           ├── P500756.webp
│   │           ├── P500757.webp
│   │           ├── P500777.webp
│   │           ├── P500778.webp
│   │           ├── P500857.webp
│   │           ├── P500894.webp
│   │           ├── P500982.webp
│   │           ├── P500988.webp
│   │           ├── P500993.webp
│   │           ├── P501005.webp
│   │           ├── P501024.webp
│   │           ├── P501028.webp
│   │           ├── P501029.webp
│   │           ├── P501030.webp
│   │           ├── P501031.webp
│   │           ├── P501157.webp
│   │           ├── P501165.webp
│   │           ├── P501166.webp
│   │           ├── P501169.webp
│   │           ├── P501170.webp
│   │           ├── P501171.webp
│   │           ├── P501176.webp
│   │           ├── P501178.webp
│   │           ├── P501185.webp
│   │           ├── P501187.webp
│   │           ├── P501188.webp
│   │           ├── P501189.webp
│   │           ├── P501190.webp
│   │           ├── P501199.webp
│   │           ├── P501213.webp
│   │           ├── P501236.webp
│   │           ├── P501243.webp
│   │           ├── P501254.webp
│   │           ├── P501282.webp
│   │           ├── P501288.webp
│   │           ├── P501316.webp
│   │           ├── P501321.webp
│   │           ├── P501421.webp
│   │           ├── P501518.webp
│   │           ├── P501581.webp
│   │           ├── P501587.webp
│   │           ├── P501760.webp
│   │           ├── P501781.webp
│   │           ├── P501790.webp
│   │           ├── P502046.webp
│   │           ├── P502169.webp
│   │           ├── P502197.webp
│   │           ├── P502200.webp
│   │           ├── P502322.webp
│   │           ├── P502326.webp
│   │           ├── P502395.webp
│   │           ├── P502479.webp
│   │           ├── P502640.webp
│   │           ├── P502656.webp
│   │           ├── P502691.webp
│   │           ├── P502710.webp
│   │           ├── P502741.webp
│   │           ├── P502745.webp
│   │           ├── P502749.webp
│   │           ├── P502756.webp
│   │           ├── P502758.webp
│   │           ├── P502761.webp
│   │           ├── P502831.webp
│   │           ├── P502848.webp
│   │           ├── P502852.webp
│   │           ├── P502966.webp
│   │           ├── P502986.webp
│   │           ├── P502997.webp
│   │           ├── P503052.webp
│   │           ├── P503191.webp
│   │           ├── P503197.webp
│   │           ├── P503250.webp
│   │           ├── P503634.webp
│   │           ├── P503642.webp
│   │           ├── P503651.webp
│   │           ├── P503652.webp
│   │           ├── P503657.webp
│   │           ├── P503668.webp
│   │           ├── P503683.webp
│   │           ├── P503690.webp
│   │           ├── P503692.webp
│   │           ├── P503693.webp
│   │           ├── P503721.webp
│   │           ├── P503726.webp
│   │           ├── P503747.webp
│   │           ├── P503809.webp
│   │           ├── P503814.webp
│   │           ├── P503827.webp
│   │           ├── P503865.webp
│   │           ├── P503867.webp
│   │           ├── P503878.webp
│   │           ├── P503879.webp
│   │           ├── P503891.webp
│   │           ├── P503913.webp
│   │           ├── P503920.webp
│   │           ├── P503923.webp
│   │           ├── P503926.webp
│   │           ├── P503927.webp
│   │           ├── P503928.webp
│   │           ├── P503936.webp
│   │           ├── P503991.webp
│   │           ├── P503992.webp
│   │           ├── P503999.webp
│   │           ├── P504001.webp
│   │           ├── P504007.webp
│   │           ├── P504016.webp
│   │           ├── P504023.webp
│   │           ├── P504026.webp
│   │           ├── P504028.webp
│   │           ├── P504031.webp
│   │           ├── P504040.webp
│   │           ├── P504042.webp
│   │           ├── P504043.webp
│   │           ├── P504044.webp
│   │           ├── P504045.webp
│   │           ├── P504050.webp
│   │           ├── P504056.webp
│   │           ├── P504059.webp
│   │           ├── P504064.webp
│   │           ├── P504071.webp
│   │           ├── P504073.webp
│   │           ├── P504076.webp
│   │           ├── P504125.webp
│   │           ├── P504134.webp
│   │           ├── P504171.webp
│   │           ├── P504199.webp
│   │           ├── P504212.webp
│   │           ├── P504218.webp
│   │           ├── P504240.webp
│   │           ├── P504277.webp
│   │           ├── P504309.webp
│   │           ├── P504313.webp
│   │           ├── P504315.webp
│   │           ├── P504325.webp
│   │           ├── P504421.webp
│   │           ├── P504429.webp
│   │           ├── P504433.webp
│   │           ├── P504446.webp
│   │           ├── P504506.webp
│   │           ├── P504523.webp
│   │           ├── P504524.webp
│   │           ├── P504575.webp
│   │           ├── P504595.webp
│   │           ├── P504615.webp
│   │           ├── P504637.webp
│   │           ├── P504639.webp
│   │           ├── P504644.webp
│   │           ├── P504773.webp
│   │           ├── P504794.webp
│   │           ├── P504849.webp
│   │           ├── P504880.webp
│   │           ├── P504892.webp
│   │           ├── P504986.webp
│   │           ├── P504988.webp
│   │           ├── P505009.webp
│   │           ├── P505020.webp
│   │           ├── P505023.webp
│   │           ├── P505024.webp
│   │           ├── P505031.webp
│   │           ├── P505047.webp
│   │           ├── P505049.webp
│   │           ├── P505054.webp
│   │           ├── P505131.webp
│   │           ├── P505133.webp
│   │           ├── P505139.webp
│   │           ├── P505140.webp
│   │           ├── P505142.webp
│   │           ├── P505145.webp
│   │           ├── P505158.webp
│   │           ├── P505160.webp
│   │           ├── P505211.webp
│   │           ├── P505233.webp
│   │           ├── P505274.webp
│   │           ├── P505316.webp
│   │           ├── P505338.webp
│   │           ├── P505346.webp
│   │           ├── P505392.webp
│   │           ├── P505452.webp
│   │           ├── P505711.webp
│   │           ├── P54509.webp
│   │           ├── P6028.webp
│   │           ├── P7365.webp
│   │           ├── P7880.webp
│   │           ├── P91627362.webp
│   │           ├── P94421.webp
│   │           ├── P94812.webp
│   │           ├── P9939.webp
│   │           ├── P9940.webp
│   │           └── P9941.webp
│   ├── exploitation/
│   │   ├── analisis_final/
│   │   ├── dashboards_data/
│   │   ├── modelos_input/
│   │   │   ├── ABSA_test_full_dataset/
│   │   │   │   ├── test/
│   │   │   │   │   └── data.parquet
│   │   │   │   ├── train/
│   │   │   │   │   └── data.parquet
│   │   │   │   └── val/
│   │   │   │       └── data.parquet
│   │   │   ├── rest_from_full/
│   │   │   │   ├── _SUCCESS
│   │   │   │   ├── part-00000-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00001-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00003-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00005-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00007-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00009-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00011-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   ├── part-00013-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   │   └── part-00015-40d0e94c-d330-490e-831b-765fb130ea32-c000.snappy.parquet
│   │   │   └── sample_tvt/
│   │   │       ├── test/
│   │   │       │   └── data.parquet
│   │   │       ├── train/
│   │   │       │   └── data.parquet
│   │   │       └── val/
│   │   │           └── data.parquet
│   │   ├── product_info_snapshot.parquet/
│   │   │   ├── _SUCCESS
│   │   │   ├── part-00000-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00001-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00002-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00003-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00004-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00005-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00006-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00007-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00008-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00009-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00010-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00011-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00012-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00013-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00014-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00015-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00016-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00017-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00018-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00019-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00020-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   ├── part-00021-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   │   └── part-00022-1a96b7eb-e30d-4524-836f-58cee8a8e354-c000.snappy.parquet
│   │   └── products/
│   ├── landing/
│   │   ├── sephora/
│   │   │   ├── delta/
│   │   │   │   ├── product_info/
│   │   │   │   │   ├── _delta_log/
│   │   │   │   │   ├── part-00000-6e6bdc20-9cb6-430c-89b2-1d8f97233026-c000.snappy.parquet
│   │   │   │   │   └── part-00001-c3a09776-91a7-498f-a39b-24cebf0dd9e2-c000.snappy.parquet
│   │   │   │   ├── reviews_0-250/
│   │   │   │   │   ├── _delta_log/
│   │   │   │   │   ├── part-00000-cd54cb22-07ce-4d9c-9684-0bb28eb44c00-c000.snappy.parquet
│   │   │   │   │   ├── part-00001-910bbe61-1c2b-4272-a450-f0a679f4fd80-c000.snappy.parquet
│   │   │   │   │   ├── part-00002-5edd5a8c-9ba1-4d32-834f-918c904ba5b5-c000.snappy.parquet
│   │   │   │   │   ├── part-00003-bc45ee52-3ea8-45c2-a7a2-776362a3af37-c000.snappy.parquet
│   │   │   │   │   ├── part-00004-d9d511cb-2490-4bb8-8234-9d886ba8255b-c000.snappy.parquet
│   │   │   │   │   ├── part-00005-2ccd8fca-e12e-4ecb-b8e1-5539166b7412-c000.snappy.parquet
│   │   │   │   │   ├── part-00006-d067bd38-783b-4719-955d-347110c929f4-c000.snappy.parquet
│   │   │   │   │   ├── part-00007-1ae86e1b-449d-4a7a-86c7-0ccbbdc96679-c000.snappy.parquet
│   │   │   │   │   ├── part-00008-23c9b5fe-6e08-4601-a8f6-df1a147e0be4-c000.snappy.parquet
│   │   │   │   │   ├── part-00009-41e5a462-d304-46da-95e9-997f5cb3f013-c000.snappy.parquet
│   │   │   │   │   ├── part-00010-fe7baeef-f90c-475c-a0dc-41bb5fbaa244-c000.snappy.parquet
│   │   │   │   │   ├── part-00011-5d96d678-9457-41c1-b077-df5b70e9ee2e-c000.snappy.parquet
│   │   │   │   │   ├── part-00012-eb30df78-f25c-4fb6-b01c-42f2458ee200-c000.snappy.parquet
│   │   │   │   │   ├── part-00013-d792109a-eaca-4f26-bfb5-a0b5f1fe67a5-c000.snappy.parquet
│   │   │   │   │   ├── part-00014-be21e10b-d5db-413f-8de6-c41ec55c5f08-c000.snappy.parquet
│   │   │   │   │   ├── part-00015-700a9b73-5681-4da2-96f3-2ef23583afa2-c000.snappy.parquet
│   │   │   │   │   ├── part-00016-b6918588-a4a8-474a-83dd-683481749711-c000.snappy.parquet
│   │   │   │   │   ├── part-00017-c785ac52-3688-486d-b32d-72e2c52f7f05-c000.snappy.parquet
│   │   │   │   │   ├── part-00018-3671e7b1-d46a-40b1-a86b-d7fbb18e92eb-c000.snappy.parquet
│   │   │   │   │   ├── part-00019-41ad29f6-a08e-42c2-90ab-df4aedd61c67-c000.snappy.parquet
│   │   │   │   │   ├── part-00020-f62e68e9-de1f-4c77-b570-a17a50964e96-c000.snappy.parquet
│   │   │   │   │   └── part-00021-3f4c571b-f80e-4f6e-9356-fa617110e82a-c000.snappy.parquet
│   │   │   │   ├── reviews_1250-end/
│   │   │   │   │   ├── _delta_log/
│   │   │   │   │   ├── part-00000-eb6e7ca4-0eff-4cfd-84ee-ea0f028e9838-c000.snappy.parquet
│   │   │   │   │   ├── part-00001-eb716a2e-35f0-4d2b-b638-473d302b9df9-c000.snappy.parquet
│   │   │   │   │   ├── part-00002-d0dd18a3-cc50-40fb-ba05-6f75b637cc90-c000.snappy.parquet
│   │   │   │   │   ├── part-00003-aa5ad103-63f2-435c-8587-57d71bac3fdb-c000.snappy.parquet
│   │   │   │   │   ├── part-00004-274f516f-ea78-4d6b-9681-f6a14768c68d-c000.snappy.parquet
│   │   │   │   │   └── part-00005-cbaee973-5b79-462b-a4d6-3b3020e5160e-c000.snappy.parquet
│   │   │   │   ├── reviews_250-500/
│   │   │   │   │   ├── _delta_log/
│   │   │   │   │   ├── part-00000-990105fa-dac5-4b21-a364-00db6184210c-c000.snappy.parquet
│   │   │   │   │   ├── part-00001-842e24e3-90df-472f-bbbb-a9c51b0462f8-c000.snappy.parquet
│   │   │   │   │   ├── part-00002-60b22349-6656-4b45-a8b5-1fe55208f55a-c000.snappy.parquet
│   │   │   │   │   ├── part-00003-307744c2-f98f-4afd-9cd2-d18c8931e314-c000.snappy.parquet
│   │   │   │   │   ├── part-00004-8672dc5c-e45c-460a-a26a-6f1382d73e7f-c000.snappy.parquet
│   │   │   │   │   ├── part-00005-a98c5cf5-ab65-475f-bdd3-f28861c50d1a-c000.snappy.parquet
│   │   │   │   │   ├── part-00006-a53f53c8-8f59-4037-9645-36e14bfa9b57-c000.snappy.parquet
│   │   │   │   │   ├── part-00007-6a39563f-10a7-48a6-89ca-8d09d7c20b4c-c000.snappy.parquet
│   │   │   │   │   ├── part-00008-9cc20405-532d-4526-aa92-000d6b00fd41-c000.snappy.parquet
│   │   │   │   │   ├── part-00009-f182d3e2-954c-4dc4-8c09-6b89084dca16-c000.snappy.parquet
│   │   │   │   │   ├── part-00010-38521f57-5543-4ff0-8674-ab25a2ecc1be-c000.snappy.parquet
│   │   │   │   │   ├── part-00011-e87a992b-2981-4eb1-b6bc-026d98c94adf-c000.snappy.parquet
│   │   │   │   │   ├── part-00012-99782dc4-fb75-496b-bc73-bf3b1488d147-c000.snappy.parquet
│   │   │   │   │   ├── part-00013-2319326a-d0dd-4d77-a235-57b654eca332-c000.snappy.parquet
│   │   │   │   │   ├── part-00014-e773d861-2501-4ef5-9034-1a3eab3fa072-c000.snappy.parquet
│   │   │   │   │   ├── part-00015-efcc5bb8-e099-4241-aa52-b7cc0e143f07-c000.snappy.parquet
│   │   │   │   │   ├── part-00016-33504e78-2c2a-4cda-b63c-7a832561f192-c000.snappy.parquet
│   │   │   │   │   ├── part-00017-8d4cbac2-941e-4ecb-8f94-e06195923a64-c000.snappy.parquet
│   │   │   │   │   ├── part-00018-ccf8769e-b2d6-4af2-a7fe-d0cbfd60efb8-c000.snappy.parquet
│   │   │   │   │   ├── part-00019-e090d52d-7724-43c8-ae5a-352695b6d88a-c000.snappy.parquet
│   │   │   │   │   ├── part-00020-9d6dd212-45dd-4a66-85be-85e3449322b0-c000.snappy.parquet
│   │   │   │   │   └── part-00021-d20e2ff2-ab84-4f9d-aee1-fca6b053795f-c000.snappy.parquet
│   │   │   │   ├── reviews_500-750/
│   │   │   │   │   ├── _delta_log/
│   │   │   │   │   ├── part-00000-3b276e46-4a78-4bb1-aed5-70d1f70ebbed-c000.snappy.parquet
│   │   │   │   │   ├── part-00001-a8e9633e-d272-49b7-81b6-8c822e4efe4a-c000.snappy.parquet
│   │   │   │   │   ├── part-00002-5558bc9b-502b-42de-945c-15818273fd5c-c000.snappy.parquet
│   │   │   │   │   ├── part-00003-97554cd3-7cab-4cce-a3e8-c5fb201ac8e6-c000.snappy.parquet
│   │   │   │   │   ├── part-00004-c70ef94e-e737-4f2b-a3a3-4529273c976d-c000.snappy.parquet
│   │   │   │   │   ├── part-00005-3a52c917-b5fd-453d-b4e5-d1a0f444e0b7-c000.snappy.parquet
│   │   │   │   │   ├── part-00006-2bb29d8a-8b97-4a98-9595-0c2bb6112139-c000.snappy.parquet
│   │   │   │   │   ├── part-00007-eac02b62-69fb-4cd9-8712-74660385398f-c000.snappy.parquet
│   │   │   │   │   ├── part-00008-40d2a05c-431c-4b99-8d94-07bd61875e8c-c000.snappy.parquet
│   │   │   │   │   ├── part-00009-d8f64819-064c-4392-8a24-2c1a402d8c31-c000.snappy.parquet
│   │   │   │   │   ├── part-00010-0bd8ed5f-e8d8-4457-9e26-a40ab992ac30-c000.snappy.parquet
│   │   │   │   │   ├── part-00011-6b4caa74-f436-4ec9-a983-80e0c4995839-c000.snappy.parquet
│   │   │   │   │   ├── part-00012-c8674a98-77da-460f-b45e-971545e8629d-c000.snappy.parquet
│   │   │   │   │   └── part-00013-9ac5368b-8599-4956-a76d-927591b77dee-c000.snappy.parquet
│   │   │   │   └── reviews_750-1250/
│   │   │   │       ├── _delta_log/
│   │   │   │       ├── part-00000-47ccddf2-a79b-4a1b-899c-00d67765458f-c000.snappy.parquet
│   │   │   │       ├── part-00001-4b20d7d2-b48f-47d6-b741-84945cfc0d60-c000.snappy.parquet
│   │   │   │       ├── part-00002-5db8db4e-a7af-4dd9-a0c1-04f5f169650d-c000.snappy.parquet
│   │   │   │       ├── part-00003-7def1ff2-a600-4e13-b214-fc7db827d546-c000.snappy.parquet
│   │   │   │       ├── part-00004-e367f329-9c08-47a0-8aca-5e1e272fb5ec-c000.snappy.parquet
│   │   │   │       ├── part-00005-ac234ded-a5b6-4522-8ece-082c411f278f-c000.snappy.parquet
│   │   │   │       ├── part-00006-c979073d-bea1-427a-84ac-a50f6956d600-c000.snappy.parquet
│   │   │   │       ├── part-00007-c88475ab-b519-47c3-b247-81a3d84f354f-c000.snappy.parquet
│   │   │   │       ├── part-00008-dd4a226d-01a0-42d9-9af8-cd2efc78e211-c000.snappy.parquet
│   │   │   │       ├── part-00009-f1659164-e3ce-4d94-8a2b-dc667a896665-c000.snappy.parquet
│   │   │   │       ├── part-00010-bcdfee8b-848b-4d64-a145-c8b0c1bd2a26-c000.snappy.parquet
│   │   │   │       ├── part-00011-3e602d72-6169-45bf-9963-b5df7272f9aa-c000.snappy.parquet
│   │   │   │       ├── part-00012-b66ddba7-addc-4bc0-8e90-4ae9f06add0e-c000.snappy.parquet
│   │   │   │       └── part-00013-4d9ff6b9-9db7-4927-9258-1c7c99c5ca85-c000.snappy.parquet
│   │   │   └── raw/
│   │   │       ├── product_info.csv
│   │   │       ├── reviews_0-250.csv
│   │   │       ├── reviews_1250-end.csv
│   │   │       ├── reviews_250-500.csv
│   │   │       ├── reviews_500-750.csv
│   │   │       └── reviews_750-1250.csv
│   │   └── ulta/
│   │       ├── delta/
│   │       │   └── Ulta Skincare Reviews/
│   │       │       ├── _delta_log/
│   │       │       ├── part-00000-010c96b2-e5af-4d2c-955d-8a4dc8253df2-c000.snappy.parquet
│   │       │       ├── part-00000-4e578caf-e36d-4aff-bba5-4c2f1126f284-c000.snappy.parquet
│   │       │       ├── part-00000-574c453e-a0f5-474c-b1a2-22056e93a1fb-c000.snappy.parquet
│   │       │       ├── part-00000-7ab2c7fd-2cd6-41d0-9382-eecc93e7bd6b-c000.snappy.parquet
│   │       │       ├── part-00000-9196b23d-e4fc-4398-89eb-97e7559776b2-c000.snappy.parquet
│   │       │       ├── part-00000-987a268e-b804-4cb9-bb44-e13e76234dcc-c000.snappy.parquet
│   │       │       ├── part-00000-9ccc5320-3923-4fbe-bb14-3fa64ed70131-c000.snappy.parquet
│   │       │       ├── part-00000-a75c285d-7cbd-41cd-871c-f947f1a9e7f1-c000.snappy.parquet
│   │       │       ├── part-00000-bccbf704-7575-450b-93ed-9aadd151d2b0-c000.snappy.parquet
│   │       │       ├── part-00000-bedaccc3-9379-4f16-8deb-bd5250ffe0ff-c000.snappy.parquet
│   │       │       ├── part-00000-d4013fb8-6bc6-4f8c-b96c-a576b7f7bcda-c000.snappy.parquet
│   │       │       ├── part-00000-e97bd882-bb17-4f14-8ae0-1c96e43b6a8f-c000.snappy.parquet
│   │       │       ├── part-00000-ec811465-b774-4a52-ae4b-d5a050768d25-c000.snappy.parquet
│   │       │       └── part-00000-f233c90f-9fd4-44e3-bd69-9e6f0a395312-c000.snappy.parquet
│   │       ├── parquet/
│   │       │   └── Ulta Skincare Reviews/
│   │       │       ├── _SUCCESS
│   │       │       └── part-00000-bbc43d03-2b49-4f88-8499-3e11e4a8e745-c000.snappy.parquet
│   │       └── raw/
│   │           └── Ulta Skincare Reviews.csv
│   └── trusted/
│       ├── ate/
│       │   ├── train.jsonl
│       │   └── valid.jsonl
│       ├── reviews_full/
│       │   ├── _delta_log/
│       │   │   ├── 00000000000000000000.json
│       │   │   └── _commits/
│       │   ├── part-00000-afd049a6-69ab-4b09-aa7f-2becc70a2f7b-c000.snappy.parquet
│       │   ├── part-00001-2f168bf6-6f0d-4f36-b147-40e1dc81cccd-c000.snappy.parquet
│       │   ├── part-00002-4e430acb-d3a1-43d7-be1e-b9c42e290ae8-c000.snappy.parquet
│       │   ├── part-00003-077f206a-c0c5-4048-a303-d9b01e387ae7-c000.snappy.parquet
│       │   ├── part-00004-90fc51a1-d1d3-4c37-982b-e6e3f91befd9-c000.snappy.parquet
│       │   ├── part-00005-67cd7aa9-fba1-4508-9c2e-8f814355737f-c000.snappy.parquet
│       │   ├── part-00006-e08e29a1-5d03-4015-b0d8-2160873f9746-c000.snappy.parquet
│       │   └── part-00007-6501e226-e2e3-4e71-987b-a74f8e2033e7-c000.snappy.parquet
│       ├── reviews_product_info_clean_full/
│       │   ├── _delta_log/
│       │   │   ├── 00000000000000000000.json
│       │   │   └── _commits/
│       │   ├── part-00000-7a735d74-ebe2-4ef7-962f-85be1f4bc28b-c000.snappy.parquet
│       │   ├── part-00001-97b02abd-3530-47c9-9b19-1e5a5b4b3cac-c000.snappy.parquet
│       │   ├── part-00003-9a4e3b41-0226-4bfc-81a5-a4184755aae0-c000.snappy.parquet
│       │   ├── part-00005-ee204c5f-ce14-4788-9d6f-76abe0c350f6-c000.snappy.parquet
│       │   ├── part-00007-96f23bc1-841c-4b4d-9ac0-aa5a1b0c4f0e-c000.snappy.parquet
│       │   ├── part-00009-3253a288-3ccb-4100-8020-e73ffab8f222-c000.snappy.parquet
│       │   ├── part-00011-de8a68dc-45d3-443b-8e44-5cb763ea9a13-c000.snappy.parquet
│       │   ├── part-00013-9f49313a-06c9-4089-8ff8-9049ab3f2019-c000.snappy.parquet
│       │   └── part-00015-43bca129-35b0-4deb-b904-e595f26460f5-c000.snappy.parquet
│       ├── reviews_sample_30pct/
│       │   ├── _delta_log/
│       │   │   ├── 00000000000000000000.json
│       │   │   └── _commits/
│       │   ├── part-00000-f61ab771-8254-48bd-9aa8-ad3ecd550631-c000.snappy.parquet
│       │   ├── part-00001-a81c56f8-2184-4159-9ded-d6504d1b8cb7-c000.snappy.parquet
│       │   ├── part-00002-06c679cf-542c-40b0-977c-4f3f8d62c9b6-c000.snappy.parquet
│       │   ├── part-00003-927d283a-1069-4482-9af4-1ae0da4d604c-c000.snappy.parquet
│       │   ├── part-00004-bb2bc784-1eaa-4ed7-a4d9-66da1e15ef1b-c000.snappy.parquet
│       │   ├── part-00005-f17474dd-14f7-4bb9-b499-e56976c3f2af-c000.snappy.parquet
│       │   ├── part-00006-10f99142-5727-4145-8400-1d807a563e92-c000.snappy.parquet
│       │   ├── part-00007-171a74ce-ba56-4a01-b88f-150dfb8c3251-c000.snappy.parquet
│       │   ├── part-00008-a833d9eb-7a33-4fd5-b873-6e7ab02b55de-c000.snappy.parquet
│       │   ├── part-00009-74cf0c8c-cc2b-4e9c-b45a-4cfe938dc090-c000.snappy.parquet
│       │   ├── part-00010-025d8b46-6642-4e8f-a415-a6b2a6b1a8ba-c000.snappy.parquet
│       │   ├── part-00011-06526f20-9fc6-4090-a7df-cad0bbac65e1-c000.snappy.parquet
│       │   ├── part-00012-67bf162d-f91e-40ce-ac72-d66c21326fdd-c000.snappy.parquet
│       │   ├── part-00013-f9e3757d-e12e-4c03-9473-3ebf9f797d95-c000.snappy.parquet
│       │   ├── part-00014-a1033601-9d3e-4041-8b30-8237aab65beb-c000.snappy.parquet
│       │   ├── part-00015-8206249a-fa72-4ec5-8c82-3d44e2d18a83-c000.snappy.parquet
│       │   ├── part-00016-a6126273-42de-4025-bcd2-c4dc23bf9f19-c000.snappy.parquet
│       │   ├── part-00017-9e4f35fa-27ec-4c01-bbbe-2a3d6f1d3d88-c000.snappy.parquet
│       │   ├── part-00018-6e826f14-7262-4e7e-a1dc-0d001f57d265-c000.snappy.parquet
│       │   ├── part-00019-b308307e-2245-48b1-80cd-10421e6bd145-c000.snappy.parquet
│       │   ├── part-00020-492c5b8a-223e-4ae2-abba-a98474c4633f-c000.snappy.parquet
│       │   ├── part-00021-208a6a74-e9fe-4051-bdde-8a1d5e147881-c000.snappy.parquet
│       │   ├── part-00022-f9327785-3358-4fab-aea0-280b52840738-c000.snappy.parquet
│       │   ├── part-00023-6673a972-401a-4370-a470-b335ee03b723-c000.snappy.parquet
│       │   ├── part-00024-d346ba1e-01d5-47e8-97c0-26405bc488b0-c000.snappy.parquet
│       │   ├── part-00025-4a953392-b448-4a26-ba17-a819557ad857-c000.snappy.parquet
│       │   ├── part-00026-0566b6f1-78c3-4ad2-b53e-d674f6267303-c000.snappy.parquet
│       │   ├── part-00027-3d18082a-4965-4c5c-8835-93e65fc0bd8b-c000.snappy.parquet
│       │   ├── part-00028-ffa3b8db-0a9a-439c-8ade-79203737d67a-c000.snappy.parquet
│       │   ├── part-00029-448495a7-657b-4eaa-92d7-5899cff2f1a7-c000.snappy.parquet
│       │   ├── part-00030-e436a941-4f27-4148-bf21-21899676949f-c000.snappy.parquet
│       │   ├── part-00031-c70d3ea0-6e75-4738-879d-538dadd68daa-c000.snappy.parquet
│       │   ├── part-00032-c839ee69-5788-47c2-b423-b8e36b3bc385-c000.snappy.parquet
│       │   ├── part-00033-21d13fdd-7726-44be-a91b-d8f2466ad27c-c000.snappy.parquet
│       │   ├── part-00034-3e837a10-673f-4e58-8cb7-7f1bd3b9a7cd-c000.snappy.parquet
│       │   ├── part-00035-0a7276b6-3be6-443f-ae5a-15609871c9f9-c000.snappy.parquet
│       │   ├── part-00036-456a8075-d2f1-4022-94b9-c4363d195d2c-c000.snappy.parquet
│       │   ├── part-00037-58cd75ac-3b37-4bf7-a6eb-2150fc8e00e1-c000.snappy.parquet
│       │   ├── part-00038-93d80049-6b10-4385-8d0e-01ff1dd284d7-c000.snappy.parquet
│       │   ├── part-00039-ef50ecd0-47d3-4919-a7ed-70a37bb2f53b-c000.snappy.parquet
│       │   ├── part-00040-b2d447e9-46b4-45d7-83bb-3fde60a13dcd-c000.snappy.parquet
│       │   ├── part-00041-f0b913fc-0df0-45ec-b6c0-dee37ce530ef-c000.snappy.parquet
│       │   ├── part-00042-dddfc96c-f5ad-4cfc-b7a2-ae9cd6fb68fb-c000.snappy.parquet
│       │   ├── part-00043-51ad79a9-ec85-464c-806d-c94096a0ce48-c000.snappy.parquet
│       │   ├── part-00044-808e46b8-8969-4093-a744-31568fbf0256-c000.snappy.parquet
│       │   ├── part-00045-362d220b-c8fe-475f-940b-f45f897b75e9-c000.snappy.parquet
│       │   ├── part-00046-94a32307-97a3-4e07-aa42-824d11a1622e-c000.snappy.parquet
│       │   ├── part-00047-0f0afb9a-884d-465f-82c7-178a712389af-c000.snappy.parquet
│       │   ├── part-00048-3cfea1fa-1ce6-4f7e-9d23-fb25b1fc88d0-c000.snappy.parquet
│       │   ├── part-00049-05af4442-66c2-49ed-865a-a273d2e790f3-c000.snappy.parquet
│       │   ├── part-00050-130cd0c6-e9cb-4f5d-89f4-a08bdd471f60-c000.snappy.parquet
│       │   ├── part-00051-27fd1891-034f-444e-a195-b16dea021a7d-c000.snappy.parquet
│       │   ├── part-00052-a5396f07-fbed-4f71-aa71-f20f1f173c1e-c000.snappy.parquet
│       │   ├── part-00053-915806ba-b2a7-400e-8c71-2e43dd5beaef-c000.snappy.parquet
│       │   ├── part-00054-deef0489-a03f-4ea6-9042-996c59e806c2-c000.snappy.parquet
│       │   ├── part-00055-0d1bc558-530b-4156-a7f4-9fcbf4037a7f-c000.snappy.parquet
│       │   ├── part-00056-5f622591-b600-450c-869f-d1d1da938634-c000.snappy.parquet
│       │   ├── part-00057-f82138ce-81e7-47cf-8478-e9f0200b49b8-c000.snappy.parquet
│       │   ├── part-00058-02e3b25a-4838-4def-af1b-2836f0ae615f-c000.snappy.parquet
│       │   ├── part-00059-f852ab1b-46ab-4137-a954-3e05aad42a7d-c000.snappy.parquet
│       │   ├── part-00060-29989d9e-8381-4481-844c-f30a1397d824-c000.snappy.parquet
│       │   ├── part-00061-38d35060-cc26-4ebf-af58-db847038361e-c000.snappy.parquet
│       │   ├── part-00062-2532e43e-c4a5-41a7-880e-8496523de67d-c000.snappy.parquet
│       │   └── part-00063-0a81a95e-dc6d-483d-8c58-d20518762f95-c000.snappy.parquet
│       ├── sephora_clean/
│       │   ├── product_info/
│       │   │   ├── _delta_log/
│       │   │   │   ├── 00000000000000000000.json
│       │   │   │   └── _commits/
│       │   │   ├── part-00000-ba051e8b-b849-4fdc-952a-da7f1d320eb1-c000.snappy.parquet
│       │   │   ├── part-00001-84000a5b-0bca-4ab3-aa95-939f008cec7f-c000.snappy.parquet
│       │   │   ├── part-00002-075d7e3a-8ab4-49b5-956b-18d3b9db9611-c000.snappy.parquet
│       │   │   ├── part-00003-671aab05-31c7-4fe2-8bc6-a86832547c04-c000.snappy.parquet
│       │   │   └── part-00004-fd8dee7b-1862-47bc-9c45-1fc6c8a0ca5a-c000.snappy.parquet
│       │   ├── reviews_0-250/
│       │   │   ├── _delta_log/
│       │   │   │   ├── 00000000000000000000.json
│       │   │   │   └── _commits/
│       │   │   ├── part-00000-38305df9-851e-451c-b9ef-b16de462a587-c000.snappy.parquet
│       │   │   ├── part-00001-0900ea18-691e-4fe9-b6cb-84a2b9a9132e-c000.snappy.parquet
│       │   │   ├── part-00002-8ab89226-3fa8-47d4-af8a-943bc2a32807-c000.snappy.parquet
│       │   │   ├── part-00003-01bfb782-65a0-4316-a032-768410137752-c000.snappy.parquet
│       │   │   ├── part-00004-d4762f46-a4a5-4c90-aea0-f1053f30931f-c000.snappy.parquet
│       │   │   ├── part-00005-f0d5efb0-a740-4396-ae2e-9cf75cf58636-c000.snappy.parquet
│       │   │   ├── part-00006-657890fb-5c70-453e-a411-eaf2afd543da-c000.snappy.parquet
│       │   │   ├── part-00007-d549ab56-977c-45c5-9c67-b08bd8499ee6-c000.snappy.parquet
│       │   │   ├── part-00008-85e2d203-3cd1-4782-af57-aa9ec877ad39-c000.snappy.parquet
│       │   │   ├── part-00009-6285d348-9f4a-4a9f-82bb-8d3d4e004fea-c000.snappy.parquet
│       │   │   ├── part-00010-8b518711-7070-41bd-aea0-00073d4d55ea-c000.snappy.parquet
│       │   │   ├── part-00011-5a81fea2-3adb-483b-89c6-924e280b9ec1-c000.snappy.parquet
│       │   │   ├── part-00012-53510c4b-55f5-4f26-b1a2-276ffd1a4902-c000.snappy.parquet
│       │   │   ├── part-00013-6bf5c342-464c-487b-bcfb-f651a194d6ed-c000.snappy.parquet
│       │   │   ├── part-00014-b9f7ed27-544b-46a1-91f4-eda154d0f1bf-c000.snappy.parquet
│       │   │   ├── part-00015-ecc76f16-7552-4f65-8729-2636a037f480-c000.snappy.parquet
│       │   │   ├── part-00016-7483221b-b07f-4901-9b00-96275441bb7b-c000.snappy.parquet
│       │   │   ├── part-00017-ea63fb20-4267-4577-999f-45358c04f535-c000.snappy.parquet
│       │   │   ├── part-00018-07b50832-30ff-40e0-9b76-88e13be7f3bd-c000.snappy.parquet
│       │   │   ├── part-00019-f6b759a2-3e53-48de-83cf-0fb39013b40b-c000.snappy.parquet
│       │   │   ├── part-00020-ceaed4ae-0c25-49a9-84d5-7c44399e9108-c000.snappy.parquet
│       │   │   ├── part-00021-40c7a000-a933-4b45-bf17-239bb2dec21d-c000.snappy.parquet
│       │   │   └── part-00022-bd04326b-65e7-454c-8aab-40cfb29a8cc7-c000.snappy.parquet
│       │   ├── reviews_1250-end/
│       │   │   ├── _delta_log/
│       │   │   │   ├── 00000000000000000000.json
│       │   │   │   └── _commits/
│       │   │   ├── part-00000-51f851e9-de1d-4570-9aee-83059d694987-c000.snappy.parquet
│       │   │   ├── part-00001-9820859a-f6d8-434b-8f78-166e07570a31-c000.snappy.parquet
│       │   │   ├── part-00002-37afcba8-a043-4f80-b394-66d5bc634e9c-c000.snappy.parquet
│       │   │   ├── part-00003-9a88ab33-7391-436e-8708-9bcf2417ad61-c000.snappy.parquet
│       │   │   ├── part-00004-ad9c2d78-2f9b-4efb-ba31-60d998f56585-c000.snappy.parquet
│       │   │   ├── part-00005-f8bc608c-b4ef-4776-9521-0cfcaaa80f28-c000.snappy.parquet
│       │   │   ├── part-00006-c7c881a3-0a39-47b3-9046-8dd1c1e3bebf-c000.snappy.parquet
│       │   │   ├── part-00007-d49f4219-8297-4584-afc7-adeb3a36bb41-c000.snappy.parquet
│       │   │   ├── part-00008-5d4a0a88-c3f1-4ac3-92f0-1a953ca66948-c000.snappy.parquet
│       │   │   ├── part-00009-4fb150b5-d579-4083-a97b-938b61b537fa-c000.snappy.parquet
│       │   │   ├── part-00010-750eebd4-7ee7-4e68-b5fd-9b5e13f09bd1-c000.snappy.parquet
│       │   │   ├── part-00011-c04919fb-4868-4272-af14-67c0a1e8f9ff-c000.snappy.parquet
│       │   │   ├── part-00012-e32decac-37a6-4d15-a3c7-eee93286a349-c000.snappy.parquet
│       │   │   ├── part-00013-d4b222e1-8c8f-4e8a-b951-af2aa878abe2-c000.snappy.parquet
│       │   │   ├── part-00014-99a58fe2-cc24-46ba-855e-8ccbf99a80c5-c000.snappy.parquet
│       │   │   ├── part-00015-4fd9e38d-f5cf-4416-9769-04eeba78c3ab-c000.snappy.parquet
│       │   │   ├── part-00016-5edeb601-61a9-4048-8bb2-9e87f75c44c7-c000.snappy.parquet
│       │   │   ├── part-00017-3d08ba05-661d-4ded-b781-59ea6f5dc5e3-c000.snappy.parquet
│       │   │   ├── part-00018-9facf493-b255-4ac6-bcca-2b789e448ea9-c000.snappy.parquet
│       │   │   ├── part-00019-633dbc90-73ec-40ef-8c03-3d447e0f8c14-c000.snappy.parquet
│       │   │   ├── part-00020-90a1683c-9663-40ed-bc9d-9143fccd88eb-c000.snappy.parquet
│       │   │   ├── part-00021-4d0f5a78-fe0b-493f-bc6a-50af67d68283-c000.snappy.parquet
│       │   │   └── part-00022-57865640-c518-4587-b597-f4b315134a72-c000.snappy.parquet
│       │   ├── reviews_250-500/
│       │   │   ├── _delta_log/
│       │   │   │   ├── 00000000000000000000.json
│       │   │   │   └── _commits/
│       │   │   ├── part-00000-60c35b44-aef9-4006-9d69-d5d4d1508bc7-c000.snappy.parquet
│       │   │   ├── part-00001-a61ad41f-a2ca-4126-96fb-eecc00975d08-c000.snappy.parquet
│       │   │   ├── part-00002-027e9637-4655-4ab6-ab49-4be89cf88b4e-c000.snappy.parquet
│       │   │   ├── part-00003-d0d37202-823d-4c99-b55c-4d870969e796-c000.snappy.parquet
│       │   │   ├── part-00004-028e4dc3-6e7d-40ce-b799-597a686aac13-c000.snappy.parquet
│       │   │   ├── part-00005-5693d13b-d38f-4e69-8628-156a05f3ace1-c000.snappy.parquet
│       │   │   ├── part-00006-d0cb9447-0c6c-41b6-a681-887bb3b4f22a-c000.snappy.parquet
│       │   │   ├── part-00007-d4852499-adc8-4336-b244-088ec70fe965-c000.snappy.parquet
│       │   │   ├── part-00008-efca23c5-bc61-47f3-b1b8-a814730461ef-c000.snappy.parquet
│       │   │   ├── part-00009-d90a6a21-1286-4129-9930-c5059d45363e-c000.snappy.parquet
│       │   │   ├── part-00010-28a82101-7d0e-463e-8f32-2e6cb7b4917d-c000.snappy.parquet
│       │   │   ├── part-00011-6452c1ab-aab5-4150-9ea5-24ded4faff7f-c000.snappy.parquet
│       │   │   ├── part-00012-1414331c-28aa-4dbe-b3b2-6a5089842315-c000.snappy.parquet
│       │   │   ├── part-00013-328e3440-8707-4100-b1cc-fb9ed5bf89f3-c000.snappy.parquet
│       │   │   ├── part-00014-f5dc5a4e-20dc-4795-9778-a17e70bd7054-c000.snappy.parquet
│       │   │   ├── part-00015-137de395-e2b8-48ee-9fbb-1cda8b8af973-c000.snappy.parquet
│       │   │   ├── part-00016-3e6631b9-3bb8-4c9a-8eaa-19ea6f72e08c-c000.snappy.parquet
│       │   │   ├── part-00017-dfbd5c89-cc2a-473c-8a1a-ed4a3dec19ed-c000.snappy.parquet
│       │   │   ├── part-00018-6ed9a2f0-cf1a-4896-a75a-0d4da6fee728-c000.snappy.parquet
│       │   │   ├── part-00019-46201313-bfd4-491a-ab72-34a86d6ce1d9-c000.snappy.parquet
│       │   │   ├── part-00020-672434e5-fee2-4e3c-a7df-e305b58bc189-c000.snappy.parquet
│       │   │   ├── part-00021-d1133944-3371-4be1-8db9-49d6a58c4664-c000.snappy.parquet
│       │   │   └── part-00022-242f5714-6bf8-4a15-9eec-f7387497c171-c000.snappy.parquet
│       │   ├── reviews_500-750/
│       │   │   ├── _delta_log/
│       │   │   │   ├── 00000000000000000000.json
│       │   │   │   └── _commits/
│       │   │   ├── part-00000-5042ed87-3f62-4562-a6dd-a04f5916e1f9-c000.snappy.parquet
│       │   │   ├── part-00001-67249785-111c-40bd-a480-b39c86274955-c000.snappy.parquet
│       │   │   ├── part-00002-b438e9d4-53af-4958-b134-015fd8cc61e1-c000.snappy.parquet
│       │   │   ├── part-00003-64a2e498-89ae-4dc4-bbd6-97679b3ea5e0-c000.snappy.parquet
│       │   │   ├── part-00004-3ba96ad0-beeb-4835-9b3b-cbf6893aa038-c000.snappy.parquet
│       │   │   ├── part-00005-7b71282d-396a-459f-8789-a782ca2cc4ce-c000.snappy.parquet
│       │   │   ├── part-00006-3bf441c0-2c50-487d-88ef-7dca1aaa416e-c000.snappy.parquet
│       │   │   ├── part-00007-bbfd46e3-8315-476f-9e49-a10a5683e20b-c000.snappy.parquet
│       │   │   ├── part-00008-fc86ee6c-bd65-48d2-a27d-52ea91e03dc4-c000.snappy.parquet
│       │   │   ├── part-00009-d6f002f3-9efe-4378-bd09-8e36e640e216-c000.snappy.parquet
│       │   │   ├── part-00010-2d4d961e-95f4-4c8f-9607-ad86371c1b08-c000.snappy.parquet
│       │   │   ├── part-00011-795765d5-4498-4748-b669-ed986ee945f1-c000.snappy.parquet
│       │   │   ├── part-00012-188f615d-8a01-48be-aa92-fd9d13007c01-c000.snappy.parquet
│       │   │   ├── part-00013-7fe37591-928c-4d69-bcc1-a91ff1b05d3b-c000.snappy.parquet
│       │   │   ├── part-00014-c95bc9dc-5cd1-43b4-b5b5-f5974c5357de-c000.snappy.parquet
│       │   │   ├── part-00015-4ea5f852-9a23-432b-acab-a8cb90c3d3c3-c000.snappy.parquet
│       │   │   ├── part-00016-a5511fd9-f5bd-489e-ab76-02d932b82ece-c000.snappy.parquet
│       │   │   ├── part-00017-a4caa221-e337-404e-9984-9f6fbcac2b59-c000.snappy.parquet
│       │   │   ├── part-00018-64b902be-b55a-49bb-afac-d893049c8771-c000.snappy.parquet
│       │   │   ├── part-00019-5d9082d6-5e1a-4c21-8ad2-6e76ae79a958-c000.snappy.parquet
│       │   │   ├── part-00020-d93dd37b-d44e-429d-97c9-a106be4871e6-c000.snappy.parquet
│       │   │   ├── part-00021-b05b8615-b605-445b-a083-bc3e70cb2a1a-c000.snappy.parquet
│       │   │   └── part-00022-4d2785be-71ff-476e-8d34-c8fecb76f773-c000.snappy.parquet
│       │   └── reviews_750-1250/
│       │       ├── _delta_log/
│       │       │   ├── 00000000000000000000.json
│       │       │   └── _commits/
│       │       ├── part-00000-90ba8c92-fc33-4ace-9a04-b2b1cf70ac92-c000.snappy.parquet
│       │       ├── part-00001-0308579a-6d50-4bc5-8673-4f921cdc7fed-c000.snappy.parquet
│       │       ├── part-00002-4e6a228b-e795-45c4-8f5f-df663b094739-c000.snappy.parquet
│       │       ├── part-00003-2d7386df-cf7c-4d9d-8b03-45d7f8d2bbe9-c000.snappy.parquet
│       │       ├── part-00004-9ea6c3a8-2457-4744-853e-f424309f400e-c000.snappy.parquet
│       │       ├── part-00005-111a342c-8e3c-4dd7-a7b0-59579ffa08b6-c000.snappy.parquet
│       │       ├── part-00006-fcd6b09c-c808-473f-9ccf-f96203003875-c000.snappy.parquet
│       │       ├── part-00007-2d6c2d82-ce19-459f-8c9d-8058ee178101-c000.snappy.parquet
│       │       ├── part-00008-ea196e8f-073f-4bef-b489-0c973ab08754-c000.snappy.parquet
│       │       ├── part-00009-94f5103f-fdf5-4850-98c9-a7be2174b0c5-c000.snappy.parquet
│       │       ├── part-00010-500076bb-c221-4131-b05c-f8b7459d745c-c000.snappy.parquet
│       │       ├── part-00011-2f0ad34d-b2a6-4b8c-8f87-315964fb5120-c000.snappy.parquet
│       │       ├── part-00012-ab61f93b-56dc-4ec7-94c9-adf5403d5afb-c000.snappy.parquet
│       │       ├── part-00013-1fea140f-1666-45a9-912d-4587064a6244-c000.snappy.parquet
│       │       ├── part-00014-480ea779-3401-465d-b5df-60f5be775254-c000.snappy.parquet
│       │       ├── part-00015-b24e6c49-bb11-43a3-9777-190b9f833717-c000.snappy.parquet
│       │       ├── part-00016-bd7a8619-5baf-46cc-a53c-a3319e740e19-c000.snappy.parquet
│       │       ├── part-00017-facad230-d49e-49d2-8bd7-c6ce99cd8829-c000.snappy.parquet
│       │       ├── part-00018-b5be1735-a569-4855-857f-17bede169ef7-c000.snappy.parquet
│       │       ├── part-00019-681d88a3-ec33-4bc5-8c44-25978e2cb0df-c000.snappy.parquet
│       │       ├── part-00020-3a928460-610b-4a03-996a-ea0d4f2bda4c-c000.snappy.parquet
│       │       ├── part-00021-fe4f8cd1-e889-4b55-965e-c9c037122849-c000.snappy.parquet
│       │       └── part-00022-5cdeee9d-1cf3-4379-a233-db888f022287-c000.snappy.parquet
│       ├── splits/
│       │   ├── manifest.json
│       │   ├── test/
│       │   │   ├── _SUCCESS
│       │   │   ├── part-00000-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   ├── part-00001-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   ├── part-00002-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   ├── part-00003-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   ├── part-00004-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   ├── part-00005-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   ├── part-00006-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   │   └── part-00007-0ad005c2-398c-478e-b319-b00215f3ad6d-c000.snappy.parquet
│       │   ├── train/
│       │   │   ├── _SUCCESS
│       │   │   ├── part-00000-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   ├── part-00001-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   ├── part-00002-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   ├── part-00003-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   ├── part-00004-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   ├── part-00005-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   ├── part-00006-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   │   └── part-00007-85845328-8eb9-438f-99b4-099604262a73-c000.snappy.parquet
│       │   └── val/
│       │       ├── _SUCCESS
│       │       ├── part-00000-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       ├── part-00001-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       ├── part-00002-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       ├── part-00003-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       ├── part-00004-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       ├── part-00005-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       ├── part-00006-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       │       └── part-00007-c7d69836-99b2-4480-9a9c-a983b8b17122-c000.snappy.parquet
│       └── ulta_clean/
│           └── Ulta Skincare Reviews/
│               ├── _delta_log/
│               │   ├── 00000000000000000000.json
│               │   ├── 00000000000000000001.json
│               │   ├── 00000000000000000002.json
│               │   ├── 00000000000000000003.json
│               │   ├── 00000000000000000004.json
│               │   ├── 00000000000000000005.json
│               │   └── _commits/
│               ├── part-00000-175f97c2-2684-4515-b084-ff561682d7cd-c000.snappy.parquet
│               ├── part-00000-3c950be7-7617-4e4d-9df5-74ad03d35ce6-c000.snappy.parquet
│               ├── part-00000-720ac06f-221e-4cfe-b421-dbbd0a6e1705-c000.snappy.parquet
│               ├── part-00000-748c0610-1008-46d2-a740-dc429d4d2795-c000.snappy.parquet
│               ├── part-00000-74d2c324-3c2b-4e86-a08c-6b6767c983c1-c000.snappy.parquet
│               └── part-00000-e1dbd9c8-6788-4862-b213-1281a9bf29b3-c000.snappy.parquet
├── dvc.lock
├── dvc.yaml
├── log dvc repro - (venv) pedro@PVS~MASTER_BIGDATATFMT.txt
├── mlruns/
│   ├── 0/
│   │   ├── 8854a58292f04b77bef57111634c51b0/
│   │   │   ├── meta.yaml
│   │   │   ├── params/
│   │   │   │   ├── _name_or_path
│   │   │   │   ├── accelerator_config
│   │   │   │   ├── adafactor
│   │   │   │   ├── adam_beta1
│   │   │   │   ├── adam_beta2
│   │   │   │   ├── adam_epsilon
│   │   │   │   ├── add_cross_attention
│   │   │   │   ├── architectures
│   │   │   │   ├── attention_probs_dropout_prob
│   │   │   │   ├── auto_find_batch_size
│   │   │   │   ├── average_tokens_across_devices
│   │   │   │   ├── bad_words_ids
│   │   │   │   ├── batch_eval_metrics
│   │   │   │   ├── begin_suppress_tokens
│   │   │   │   ├── bf16
│   │   │   │   ├── bf16_full_eval
│   │   │   │   ├── bos_token_id
│   │   │   │   ├── chunk_size_feed_forward
│   │   │   │   ├── classifier_dropout_prob
│   │   │   │   ├── cross_attention_hidden_size
│   │   │   │   ├── data_seed
│   │   │   │   ├── dataloader_drop_last
│   │   │   │   ├── dataloader_num_workers
│   │   │   │   ├── dataloader_persistent_workers
│   │   │   │   ├── dataloader_pin_memory
│   │   │   │   ├── dataloader_prefetch_factor
│   │   │   │   ├── ddp_backend
│   │   │   │   ├── ddp_broadcast_buffers
│   │   │   │   ├── ddp_bucket_cap_mb
│   │   │   │   ├── ddp_find_unused_parameters
│   │   │   │   ├── ddp_timeout
│   │   │   │   ├── debug
│   │   │   │   ├── decoder_start_token_id
│   │   │   │   ├── deepspeed
│   │   │   │   ├── disable_tqdm
│   │   │   │   ├── diversity_penalty
│   │   │   │   ├── do_eval
│   │   │   │   ├── do_predict
│   │   │   │   ├── do_sample
│   │   │   │   ├── do_train
│   │   │   │   ├── down_scale_factor
│   │   │   │   ├── dtype
│   │   │   │   ├── early_stopping
│   │   │   │   ├── embedding_size
│   │   │   │   ├── encoder_no_repeat_ngram_size
│   │   │   │   ├── eos_token_id
│   │   │   │   ├── eval_accumulation_steps
│   │   │   │   ├── eval_delay
│   │   │   │   ├── eval_do_concat_batches
│   │   │   │   ├── eval_on_start
│   │   │   │   ├── eval_steps
│   │   │   │   ├── eval_strategy
│   │   │   │   ├── eval_use_gather_object
│   │   │   │   ├── exponential_decay_length_penalty
│   │   │   │   ├── finetuning_task
│   │   │   │   ├── forced_bos_token_id
│   │   │   │   ├── forced_eos_token_id
│   │   │   │   ├── fp16
│   │   │   │   ├── fp16_backend
│   │   │   │   ├── fp16_full_eval
│   │   │   │   ├── fp16_opt_level
│   │   │   │   ├── fsdp
│   │   │   │   ├── fsdp_config
│   │   │   │   ├── fsdp_min_num_params
│   │   │   │   ├── fsdp_transformer_layer_cls_to_wrap
│   │   │   │   ├── full_determinism
│   │   │   │   ├── gap_size
│   │   │   │   ├── gradient_accumulation_steps
│   │   │   │   ├── gradient_checkpointing
│   │   │   │   ├── gradient_checkpointing_kwargs
│   │   │   │   ├── greater_is_better
│   │   │   │   ├── group_by_length
│   │   │   │   ├── half_precision_backend
│   │   │   │   ├── hidden_act
│   │   │   │   ├── hidden_dropout_prob
│   │   │   │   ├── hidden_size
│   │   │   │   ├── hub_always_push
│   │   │   │   ├── hub_model_id
│   │   │   │   ├── hub_private_repo
│   │   │   │   ├── hub_revision
│   │   │   │   ├── hub_strategy
│   │   │   │   ├── hub_token
│   │   │   │   ├── id2label
│   │   │   │   ├── ignore_data_skip
│   │   │   │   ├── include_for_metrics
│   │   │   │   ├── include_inputs_for_metrics
│   │   │   │   ├── include_num_input_tokens_seen
│   │   │   │   ├── include_tokens_per_second
│   │   │   │   ├── initializer_range
│   │   │   │   ├── inner_group_num
│   │   │   │   ├── intermediate_size
│   │   │   │   ├── is_decoder
│   │   │   │   ├── is_encoder_decoder
│   │   │   │   ├── jit_mode_eval
│   │   │   │   ├── label2id
│   │   │   │   ├── label_names
│   │   │   │   ├── label_smoothing_factor
│   │   │   │   ├── layer_norm_eps
│   │   │   │   ├── learning_rate
│   │   │   │   ├── length_column_name
│   │   │   │   ├── length_penalty
│   │   │   │   ├── liger_kernel_config
│   │   │   │   ├── load_best_model_at_end
│   │   │   │   ├── local_rank
│   │   │   │   ├── log_level
│   │   │   │   ├── log_level_replica
│   │   │   │   ├── log_on_each_node
│   │   │   │   ├── logging_dir
│   │   │   │   ├── logging_first_step
│   │   │   │   ├── logging_nan_inf_filter
│   │   │   │   ├── logging_steps
│   │   │   │   ├── logging_strategy
│   │   │   │   ├── lr_scheduler_kwargs
│   │   │   │   ├── lr_scheduler_type
│   │   │   │   ├── max_grad_norm
│   │   │   │   ├── max_length
│   │   │   │   ├── max_position_embeddings
│   │   │   │   ├── max_steps
│   │   │   │   ├── metric_for_best_model
│   │   │   │   ├── min_length
│   │   │   │   ├── model_type
│   │   │   │   ├── mp_parameters
│   │   │   │   ├── neftune_noise_alpha
│   │   │   │   ├── net_structure_type
│   │   │   │   ├── no_cuda
│   │   │   │   ├── no_repeat_ngram_size
│   │   │   │   ├── num_attention_heads
│   │   │   │   ├── num_beam_groups
│   │   │   │   ├── num_beams
│   │   │   │   ├── num_hidden_groups
│   │   │   │   ├── num_hidden_layers
│   │   │   │   ├── num_memory_blocks
│   │   │   │   ├── num_return_sequences
│   │   │   │   ├── num_train_epochs
│   │   │   │   ├── optim
│   │   │   │   ├── optim_args
│   │   │   │   ├── optim_target_modules
│   │   │   │   ├── output_attentions
│   │   │   │   ├── output_dir
│   │   │   │   ├── output_hidden_states
│   │   │   │   ├── output_scores
│   │   │   │   ├── overwrite_output_dir
│   │   │   │   ├── pad_token_id
│   │   │   │   ├── parallelism_config
│   │   │   │   ├── past_index
│   │   │   │   ├── per_device_eval_batch_size
│   │   │   │   ├── per_device_train_batch_size
│   │   │   │   ├── per_gpu_eval_batch_size
│   │   │   │   ├── per_gpu_train_batch_size
│   │   │   │   ├── position_embedding_type
│   │   │   │   ├── prediction_loss_only
│   │   │   │   ├── prefix
│   │   │   │   ├── problem_type
│   │   │   │   ├── pruned_heads
│   │   │   │   ├── push_to_hub
│   │   │   │   ├── push_to_hub_model_id
│   │   │   │   ├── push_to_hub_organization
│   │   │   │   ├── push_to_hub_token
│   │   │   │   ├── ray_scope
│   │   │   │   ├── remove_invalid_values
│   │   │   │   ├── remove_unused_columns
│   │   │   │   ├── repetition_penalty
│   │   │   │   ├── report_to
│   │   │   │   ├── restore_callback_states_from_checkpoint
│   │   │   │   ├── resume_from_checkpoint
│   │   │   │   ├── return_dict
│   │   │   │   ├── return_dict_in_generate
│   │   │   │   ├── run_name
│   │   │   │   ├── save_on_each_node
│   │   │   │   ├── save_only_model
│   │   │   │   ├── save_safetensors
│   │   │   │   ├── save_steps
│   │   │   │   ├── save_strategy
│   │   │   │   ├── save_total_limit
│   │   │   │   ├── seed
│   │   │   │   ├── sep_token_id
│   │   │   │   ├── skip_memory_metrics
│   │   │   │   ├── suppress_tokens
│   │   │   │   ├── task_specific_params
│   │   │   │   ├── temperature
│   │   │   │   ├── tf32
│   │   │   │   ├── tf_legacy_loss
│   │   │   │   ├── tie_encoder_decoder
│   │   │   │   ├── tie_word_embeddings
│   │   │   │   ├── tokenizer_class
│   │   │   │   ├── top_k
│   │   │   │   ├── top_p
│   │   │   │   ├── torch_compile
│   │   │   │   ├── torch_compile_backend
│   │   │   │   ├── torch_compile_mode
│   │   │   │   ├── torch_empty_cache_steps
│   │   │   │   ├── torchdynamo
│   │   │   │   ├── torchscript
│   │   │   │   ├── tpu_metrics_debug
│   │   │   │   ├── tpu_num_cores
│   │   │   │   ├── transformers_version
│   │   │   │   ├── type_vocab_size
│   │   │   │   ├── typical_p
│   │   │   │   ├── use_bfloat16
│   │   │   │   ├── use_cpu
│   │   │   │   ├── use_ipex
│   │   │   │   ├── use_legacy_prediction_loop
│   │   │   │   ├── use_liger_kernel
│   │   │   │   ├── use_mps_device
│   │   │   │   ├── vocab_size
│   │   │   │   ├── warmup_ratio
│   │   │   │   ├── warmup_steps
│   │   │   │   └── weight_decay
│   │   │   └── tags/
│   │   │       ├── mlflow.runName
│   │   │       ├── mlflow.source.git.commit
│   │   │       ├── mlflow.source.name
│   │   │       ├── mlflow.source.type
│   │   │       └── mlflow.user
│   │   └── meta.yaml
│   └── 617982129711042592/
│       ├── 13dd99e311ce4088b3a87dcf6e650afa/
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── batch
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── grad_accum
│       │   │   ├── label_col_req
│       │   │   ├── label_smoothing_factor
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── model_name
│       │   │   ├── num_labels_yaml
│       │   │   ├── optim
│       │   │   ├── patience
│       │   │   ├── rating_col_req
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── resume_from_last
│       │   │   ├── text_col_req
│       │   │   ├── warmup_ratio
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 1bc24f2e020a4f779478930b9dda6e26/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-1b74e84a778b4d2883e206a5408c9779/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 202e1ca5ae9348f48052ceffa6b1d29c/
│       │   ├── meta.yaml
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 286fadb4254e4bf2bd2b2c7f9e64bf8b/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-e3a3398fbd9946b298bdaebbf2f38bad/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 3c9ce3d610804a5cb4280347d65350a1/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-adfa443ec4b242e394ff91f8514a0c92/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 415c92b24b9445a6bf5a47909d16c1c5/
│       │   ├── artifacts/
│       │   │   ├── preprocess_config.json
│       │   │   └── val_predictions.parquet
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── val_accuracy
│       │   │   └── val_f1_macro
│       │   ├── params/
│       │   │   └── seed
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       └── mlflow.user
│       ├── 47a85146d6a54d3582aba094a04823ea/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 47be72563acc41b9b2780a956dc94df9/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-e5b0feb15032463983c8a11f641ef10c/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 4bcd2e4ffbef4cccb7c9f9cb3c2cd316/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   ├── m-7c4c2b62c5f94756bd095cf9895c592f/
│       │   │   │   └── meta.yaml
│       │   │   └── m-b5d7b82c577a46978460a2b7b9f30829/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_batch
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 59146ded54b64fb0bc1258bf59686248/
│       │   ├── artifacts/
│       │   │   └── class_weights.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── batch
│       │   │   ├── bf16
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_strategy
│       │   │   ├── fp16
│       │   │   ├── grad_accum
│       │   │   ├── gradient_checkpointing
│       │   │   ├── label_col_req
│       │   │   ├── load_best_model_at_end
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── max_len
│       │   │   ├── model_name
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── optim
│       │   │   ├── patience
│       │   │   ├── rating_col_req
│       │   │   ├── resume_from_last
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── text_col_req
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── warmup_ratio
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 5a92631ae31349259159835933abe308/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   ├── model/
│       │   │   │   ├── checkpoint-11535/
│       │   │   │   ├── checkpoint-7690/
│       │   │   │   ├── config.json
│       │   │   │   ├── special_tokens_map.json
│       │   │   │   ├── spiece.model
│       │   │   │   ├── tokenizer.json
│       │   │   │   └── tokenizer_config.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   └── train_steps_per_second
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 6e0cdd3a1a204c49bc975cc18db13e0f/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 734d4355aad6467990744b12d316f5c8/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── decoder_start_token_id
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_checkpointing
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── patience
│       │   │   ├── position_embedding_type
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── repetition_penalty
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torchscript
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_liger_kernel
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 74a6f70ce30a4300a053b243e0c56cf1/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-8f3a6032289546d1b727529533d262ca/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_batch
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 7b1b3409cea2419992196e5978d0b229/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 7b2739252c6f439ea297d015426d7e30/
│       │   ├── artifacts/
│       │   │   ├── preprocess_config.json
│       │   │   └── val_predictions.parquet
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── val_accuracy
│       │   │   └── val_f1_macro
│       │   ├── params/
│       │   │   └── seed
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       └── mlflow.user
│       ├── 7f5ec5c78a9b4273922626eaadfc9f1f/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   ├── model/
│       │   │   │   ├── checkpoint-10755/
│       │   │   │   ├── checkpoint-7170/
│       │   │   │   ├── config.json
│       │   │   │   ├── special_tokens_map.json
│       │   │   │   ├── spiece.model
│       │   │   │   ├── tokenizer.json
│       │   │   │   └── tokenizer_config.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   └── train_steps_per_second
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 80fe05bcb8f64b90afc51e42ba609f83/
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── val_accuracy
│       │   │   └── val_f1_macro
│       │   ├── params/
│       │   │   ├── feat_add_contrast_markers
│       │   │   ├── feat_add_len
│       │   │   ├── feat_add_neg_lexicon
│       │   │   ├── rf_class_weight
│       │   │   ├── rf_max_depth
│       │   │   ├── rf_n_estimators
│       │   │   ├── rf_n_jobs
│       │   │   ├── seed
│       │   │   ├── tfidf_max_df
│       │   │   ├── tfidf_max_features
│       │   │   ├── tfidf_min_df
│       │   │   ├── tfidf_ngram_range
│       │   │   └── tfidf_stop_words
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       └── mlflow.user
│       ├── 82e59bf93cb7475bb719e7b1f5ed13b8/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-bc9dd1e55d8c42f1adc8333799f60238/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 831c729c24ad4d56bcfa025c4ba62266/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   └── loss
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 8a992992e15d4cef92bf74d36dd0965d/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   ├── model/
│       │   │   │   ├── checkpoint-10755/
│       │   │   │   ├── checkpoint-14340/
│       │   │   │   ├── config.json
│       │   │   │   ├── special_tokens_map.json
│       │   │   │   ├── spiece.model
│       │   │   │   ├── tokenizer.json
│       │   │   │   └── tokenizer_config.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   └── train_steps_per_second
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 8f0f089fefc64ceca4bcac8a568e9117/
│       │   ├── artifacts/
│       │   │   └── class_weights.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── batch
│       │   │   ├── bf16
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_strategy
│       │   │   ├── fp16
│       │   │   ├── grad_accum
│       │   │   ├── gradient_checkpointing
│       │   │   ├── label_col_req
│       │   │   ├── load_best_model_at_end
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── max_len
│       │   │   ├── model_name
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── optim
│       │   │   ├── patience
│       │   │   ├── rating_col_req
│       │   │   ├── resume_from_last
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── text_col_req
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── warmup_ratio
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── 9fd4c008c715431296faa961f8a6a66c/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   ├── model/
│       │   │   │   ├── checkpoint-11262/
│       │   │   │   ├── checkpoint-15016/
│       │   │   │   ├── config.json
│       │   │   │   ├── special_tokens_map.json
│       │   │   │   ├── spiece.model
│       │   │   │   ├── tokenizer.json
│       │   │   │   └── tokenizer_config.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   └── train_steps_per_second
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── a95c69634d544979ad74b6b171262af7/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-7c839af06b20409680331512ecf0e858/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── aec07fb963f54e9fa4daf6589532eac4/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── position_embedding_type
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── b500fb2e6ce744df92c3c23f23ccd03f/
│       │   ├── artifacts/
│       │   │   ├── preprocess_config.json
│       │   │   └── val_predictions.parquet
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── val_accuracy
│       │   │   └── val_f1_macro
│       │   ├── params/
│       │   │   └── seed
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       └── mlflow.user
│       ├── b80184de488c46fdbb57b492a3235200/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-1823ee7ca44a4b669dadcec7bcb364b4/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── c6dd59c5fb6b4e549ad64369385d3d77/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_batch
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── d01c9d5e7acb445986914f7feaaa9d6e/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-9401c2ce4e7444a0aec3e6f6f40e13da/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── d542de68c9de4d18b8e733c0743a38b9/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   └── train_steps_per_second
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── dc68a21d02384287b7480eafae3083d4/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-eecf29cc9c454659b9e63804c76e0a78/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_batch
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── e11e3d13d82e4baf8a22ed84edd2ce64/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── batch
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── grad_accum
│       │   │   ├── label_col_req
│       │   │   ├── lr
│       │   │   ├── max_len
│       │   │   ├── model_name
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── optim
│       │   │   ├── patience
│       │   │   ├── rating_col_req
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── resume_from_last
│       │   │   ├── text_col_req
│       │   │   ├── warmup_ratio
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── e39f165ce8164af5b761610ee2a8e201/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   └── loss
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── e53bd876d9aa4785a49c1db23ad838bf/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-dd0122f77cb54c0ba5ee9851f0967301/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── e607f4c6bc6a4c00ad5f60f94073bf9c/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── e843a59cad48477596772f7adec1a3dd/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   └── train_steps_per_second
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── f84eadcfdc0a448d8278e37dfde19f2a/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   ├── m-6a0f854b1ffc43d89415bcd2a5826b77/
│       │   │   │   └── meta.yaml
│       │   │   └── m-9e84ac82cb2e4a9cb256844a8e345c07/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_batch
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── include_tokens_per_second
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── fa2363dc1a99488087840fd02ab47206/
│       │   ├── artifacts/
│       │   │   ├── preprocess_config.json
│       │   │   └── val_predictions.parquet
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── val_accuracy
│       │   │   └── val_f1_macro
│       │   ├── params/
│       │   │   └── seed
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       └── mlflow.user
│       ├── fbdeb13aa6b74da4aa2903643cf842c9/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── adafactor
│       │   │   ├── adam_beta1
│       │   │   ├── adam_beta2
│       │   │   ├── adam_epsilon
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── auto_find_batch_size
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_persistent_workers
│       │   │   ├── dataloader_pin_memory
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── ddp_broadcast_buffers
│       │   │   ├── ddp_bucket_cap_mb
│       │   │   ├── ddp_find_unused_parameters
│       │   │   ├── ddp_timeout
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_eval
│       │   │   ├── do_predict
│       │   │   ├── do_sample
│       │   │   ├── do_train
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── embedding_size
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_accumulation_steps
│       │   │   ├── eval_batch
│       │   │   ├── eval_delay
│       │   │   ├── eval_do_concat_batches
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_strategy
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_backend
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── full_determinism
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── gradient_accumulation_steps
│       │   │   ├── gradient_checkpointing
│       │   │   ├── gradient_checkpointing_kwargs
│       │   │   ├── greater_is_better
│       │   │   ├── group_by_length
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── hub_always_push
│       │   │   ├── hub_model_id
│       │   │   ├── hub_private_repo
│       │   │   ├── hub_revision
│       │   │   ├── hub_strategy
│       │   │   ├── hub_token
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_for_metrics
│       │   │   ├── include_inputs_for_metrics
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── learning_rate
│       │   │   ├── length_column_name
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── mp_parameters
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── num_train_epochs
│       │   │   ├── optim
│       │   │   ├── optim_args
│       │   │   ├── optim_target_modules
│       │   │   ├── output_attentions
│       │   │   ├── output_dir
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── overwrite_output_dir
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── per_device_eval_batch_size
│       │   │   ├── per_device_train_batch_size
│       │   │   ├── per_gpu_eval_batch_size
│       │   │   ├── per_gpu_train_batch_size
│       │   │   ├── position_embedding_type
│       │   │   ├── prediction_loss_only
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── push_to_hub
│       │   │   ├── push_to_hub_model_id
│       │   │   ├── push_to_hub_organization
│       │   │   ├── push_to_hub_token
│       │   │   ├── rating_col_req
│       │   │   ├── ray_scope
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── report_to
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── skip_memory_metrics
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torch_compile
│       │   │   ├── torch_compile_backend
│       │   │   ├── torch_compile_mode
│       │   │   ├── torch_empty_cache_steps
│       │   │   ├── torchdynamo
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cache
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_legacy_prediction_loop
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── fc150341769545bbbe850974dfab5cd7/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── eval_accuracy
│       │   │   ├── eval_f1_macro
│       │   │   ├── eval_loss
│       │   │   ├── eval_precision_macro
│       │   │   ├── eval_recall_macro
│       │   │   ├── eval_runtime
│       │   │   ├── eval_samples_per_second
│       │   │   ├── eval_steps_per_second
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   ├── loss
│       │   │   ├── total_flos
│       │   │   ├── train_loss
│       │   │   ├── train_runtime
│       │   │   ├── train_samples_per_second
│       │   │   ├── train_steps_per_second
│       │   │   ├── val_accuracy
│       │   │   ├── val_f1_macro
│       │   │   ├── val_loss
│       │   │   ├── val_precision_macro
│       │   │   └── val_recall_macro
│       │   ├── outputs/
│       │   │   └── m-5d670ee352f54f15994f88f1dd2ebaf2/
│       │   │       └── meta.yaml
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── feb60a6621e6464d8bc782931cab5c52/
│       │   ├── artifacts/
│       │   │   ├── class_weights.json
│       │   │   └── training_args_effective.json
│       │   ├── meta.yaml
│       │   ├── metrics/
│       │   │   ├── epoch
│       │   │   ├── grad_norm
│       │   │   ├── learning_rate
│       │   │   └── loss
│       │   ├── params/
│       │   │   ├── _name_or_path
│       │   │   ├── accelerator_config
│       │   │   ├── add_cross_attention
│       │   │   ├── architectures
│       │   │   ├── attention_probs_dropout_prob
│       │   │   ├── average_tokens_across_devices
│       │   │   ├── bad_words_ids
│       │   │   ├── batch
│       │   │   ├── batch_eval_metrics
│       │   │   ├── begin_suppress_tokens
│       │   │   ├── bf16
│       │   │   ├── bf16_full_eval
│       │   │   ├── bos_token_id
│       │   │   ├── chunk_size_feed_forward
│       │   │   ├── classifier_dropout_prob
│       │   │   ├── cross_attention_hidden_size
│       │   │   ├── cw_alpha
│       │   │   ├── cw_mode
│       │   │   ├── data_seed
│       │   │   ├── dataloader_drop_last
│       │   │   ├── dataloader_num_workers
│       │   │   ├── dataloader_prefetch_factor
│       │   │   ├── ddp_backend
│       │   │   ├── debug
│       │   │   ├── decoder_start_token_id
│       │   │   ├── deepspeed
│       │   │   ├── disable_tqdm
│       │   │   ├── diversity_penalty
│       │   │   ├── do_sample
│       │   │   ├── down_scale_factor
│       │   │   ├── dtype
│       │   │   ├── early_stopping
│       │   │   ├── effective_eval_strategy
│       │   │   ├── effective_load_best_model_at_end
│       │   │   ├── effective_save_strategy
│       │   │   ├── effective_torch_compile
│       │   │   ├── effective_torch_compile_backend
│       │   │   ├── effective_torch_compile_mode
│       │   │   ├── embedding_size
│       │   │   ├── enable_logit_adjustment
│       │   │   ├── encoder_no_repeat_ngram_size
│       │   │   ├── eos_token_id
│       │   │   ├── epochs
│       │   │   ├── eval_batch
│       │   │   ├── eval_on_start
│       │   │   ├── eval_steps
│       │   │   ├── eval_use_gather_object
│       │   │   ├── exponential_decay_length_penalty
│       │   │   ├── finetuning_task
│       │   │   ├── focal_enable
│       │   │   ├── focal_gamma
│       │   │   ├── forced_bos_token_id
│       │   │   ├── forced_eos_token_id
│       │   │   ├── fp16
│       │   │   ├── fp16_full_eval
│       │   │   ├── fp16_opt_level
│       │   │   ├── fsdp
│       │   │   ├── fsdp_config
│       │   │   ├── fsdp_min_num_params
│       │   │   ├── fsdp_transformer_layer_cls_to_wrap
│       │   │   ├── gap_size
│       │   │   ├── grad_accum
│       │   │   ├── greater_is_better
│       │   │   ├── half_precision_backend
│       │   │   ├── hidden_act
│       │   │   ├── hidden_dropout_prob
│       │   │   ├── hidden_size
│       │   │   ├── id2label
│       │   │   ├── ignore_data_skip
│       │   │   ├── include_num_input_tokens_seen
│       │   │   ├── initializer_range
│       │   │   ├── inner_group_num
│       │   │   ├── intermediate_size
│       │   │   ├── is_decoder
│       │   │   ├── is_encoder_decoder
│       │   │   ├── jit_mode_eval
│       │   │   ├── label2id
│       │   │   ├── label_col_req
│       │   │   ├── label_names
│       │   │   ├── label_smoothing_factor
│       │   │   ├── layer_norm_eps
│       │   │   ├── length_penalty
│       │   │   ├── liger_kernel_config
│       │   │   ├── load_best_model_at_end
│       │   │   ├── local_rank
│       │   │   ├── log_level
│       │   │   ├── log_level_replica
│       │   │   ├── log_on_each_node
│       │   │   ├── logging_dir
│       │   │   ├── logging_first_step
│       │   │   ├── logging_nan_inf_filter
│       │   │   ├── logging_steps
│       │   │   ├── logging_strategy
│       │   │   ├── logit_adjustment_tau
│       │   │   ├── lr
│       │   │   ├── lr_scheduler_kwargs
│       │   │   ├── lr_scheduler_type
│       │   │   ├── max_grad_norm_req
│       │   │   ├── max_len
│       │   │   ├── max_length
│       │   │   ├── max_position_embeddings
│       │   │   ├── max_steps
│       │   │   ├── metric_for_best_model
│       │   │   ├── min_length
│       │   │   ├── model_name
│       │   │   ├── model_type
│       │   │   ├── neftune_noise_alpha
│       │   │   ├── net_structure_type
│       │   │   ├── no_cuda
│       │   │   ├── no_repeat_ngram_size
│       │   │   ├── num_attention_heads
│       │   │   ├── num_beam_groups
│       │   │   ├── num_beams
│       │   │   ├── num_hidden_groups
│       │   │   ├── num_hidden_layers
│       │   │   ├── num_labels_inferred
│       │   │   ├── num_labels_yaml
│       │   │   ├── num_memory_blocks
│       │   │   ├── num_return_sequences
│       │   │   ├── optim
│       │   │   ├── optim_target_modules
│       │   │   ├── output_hidden_states
│       │   │   ├── output_scores
│       │   │   ├── pad_token_id
│       │   │   ├── parallelism_config
│       │   │   ├── past_index
│       │   │   ├── patience
│       │   │   ├── prefix
│       │   │   ├── problem_type
│       │   │   ├── pruned_heads
│       │   │   ├── rating_col_req
│       │   │   ├── remove_invalid_values
│       │   │   ├── remove_unused_columns
│       │   │   ├── repetition_penalty
│       │   │   ├── requested_bf16
│       │   │   ├── requested_fp16
│       │   │   ├── requested_gradient_checkpointing
│       │   │   ├── requested_logging_steps
│       │   │   ├── requested_logging_strategy
│       │   │   ├── requested_save_total_limit
│       │   │   ├── requested_torch_compile
│       │   │   ├── requested_torch_compile_backend
│       │   │   ├── requested_torch_compile_mode
│       │   │   ├── restore_callback_states_from_checkpoint
│       │   │   ├── resume_from_last
│       │   │   ├── return_dict
│       │   │   ├── return_dict_in_generate
│       │   │   ├── run_name
│       │   │   ├── save_on_each_node
│       │   │   ├── save_only_model
│       │   │   ├── save_safetensors
│       │   │   ├── save_steps
│       │   │   ├── save_strategy
│       │   │   ├── save_total_limit
│       │   │   ├── seed
│       │   │   ├── sep_token_id
│       │   │   ├── suppress_tokens
│       │   │   ├── task_specific_params
│       │   │   ├── temperature
│       │   │   ├── text_col_req
│       │   │   ├── tf32
│       │   │   ├── tf_legacy_loss
│       │   │   ├── tie_encoder_decoder
│       │   │   ├── tie_word_embeddings
│       │   │   ├── tokenizer_class
│       │   │   ├── top_k
│       │   │   ├── top_p
│       │   │   ├── torchscript
│       │   │   ├── tpu_metrics_debug
│       │   │   ├── tpu_num_cores
│       │   │   ├── transformers_version
│       │   │   ├── type_vocab_size
│       │   │   ├── typical_p
│       │   │   ├── use_bfloat16
│       │   │   ├── use_cpu
│       │   │   ├── use_ipex
│       │   │   ├── use_liger_kernel
│       │   │   ├── use_mps_device
│       │   │   ├── vocab_size
│       │   │   ├── warmup_ratio
│       │   │   ├── warmup_steps
│       │   │   └── weight_decay
│       │   └── tags/
│       │       ├── mlflow.runName
│       │       ├── mlflow.source.git.commit
│       │       ├── mlflow.source.name
│       │       ├── mlflow.source.type
│       │       ├── mlflow.user
│       │       └── stage
│       ├── meta.yaml
│       └── models/
│           ├── m-1823ee7ca44a4b669dadcec7bcb364b4/
│           │   ├── artifacts/
│           │   │   ├── LICENSE.txt
│           │   │   ├── MLmodel
│           │   │   ├── components/
│           │   │   ├── conda.yaml
│           │   │   ├── model/
│           │   │   ├── model_card.md
│           │   │   ├── model_card_data.yaml
│           │   │   ├── python_env.yaml
│           │   │   └── requirements.txt
│           │   ├── meta.yaml
│           │   ├── metrics/
│           │   │   ├── val_accuracy
│           │   │   ├── val_f1_macro
│           │   │   ├── val_loss
│           │   │   ├── val_precision_macro
│           │   │   └── val_recall_macro
│           │   ├── params/
│           │   │   ├── _name_or_path
│           │   │   ├── accelerator_config
│           │   │   ├── add_cross_attention
│           │   │   ├── architectures
│           │   │   ├── attention_probs_dropout_prob
│           │   │   ├── average_tokens_across_devices
│           │   │   ├── bad_words_ids
│           │   │   ├── batch
│           │   │   ├── batch_eval_metrics
│           │   │   ├── begin_suppress_tokens
│           │   │   ├── bf16
│           │   │   ├── bf16_full_eval
│           │   │   ├── bos_token_id
│           │   │   ├── chunk_size_feed_forward
│           │   │   ├── classifier_dropout_prob
│           │   │   ├── cross_attention_hidden_size
│           │   │   ├── cw_alpha
│           │   │   ├── cw_mode
│           │   │   ├── data_seed
│           │   │   ├── dataloader_drop_last
│           │   │   ├── dataloader_num_workers
│           │   │   ├── dataloader_prefetch_factor
│           │   │   ├── ddp_backend
│           │   │   ├── debug
│           │   │   ├── decoder_start_token_id
│           │   │   ├── deepspeed
│           │   │   ├── disable_tqdm
│           │   │   ├── diversity_penalty
│           │   │   ├── do_sample
│           │   │   ├── down_scale_factor
│           │   │   ├── dtype
│           │   │   ├── early_stopping
│           │   │   ├── effective_eval_strategy
│           │   │   ├── effective_load_best_model_at_end
│           │   │   ├── effective_save_strategy
│           │   │   ├── effective_torch_compile
│           │   │   ├── effective_torch_compile_backend
│           │   │   ├── effective_torch_compile_mode
│           │   │   ├── embedding_size
│           │   │   ├── enable_logit_adjustment
│           │   │   ├── encoder_no_repeat_ngram_size
│           │   │   ├── eos_token_id
│           │   │   ├── epochs
│           │   │   ├── eval_batch
│           │   │   ├── eval_on_start
│           │   │   ├── eval_steps
│           │   │   ├── eval_use_gather_object
│           │   │   ├── exponential_decay_length_penalty
│           │   │   ├── finetuning_task
│           │   │   ├── focal_enable
│           │   │   ├── focal_gamma
│           │   │   ├── forced_bos_token_id
│           │   │   ├── forced_eos_token_id
│           │   │   ├── fp16
│           │   │   ├── fp16_full_eval
│           │   │   ├── fp16_opt_level
│           │   │   ├── fsdp
│           │   │   ├── fsdp_config
│           │   │   ├── fsdp_min_num_params
│           │   │   ├── fsdp_transformer_layer_cls_to_wrap
│           │   │   ├── gap_size
│           │   │   ├── grad_accum
│           │   │   ├── greater_is_better
│           │   │   ├── half_precision_backend
│           │   │   ├── hidden_act
│           │   │   ├── hidden_dropout_prob
│           │   │   ├── hidden_size
│           │   │   ├── id2label
│           │   │   ├── ignore_data_skip
│           │   │   ├── include_num_input_tokens_seen
│           │   │   ├── initializer_range
│           │   │   ├── inner_group_num
│           │   │   ├── intermediate_size
│           │   │   ├── is_decoder
│           │   │   ├── is_encoder_decoder
│           │   │   ├── jit_mode_eval
│           │   │   ├── label2id
│           │   │   ├── label_col_req
│           │   │   ├── label_names
│           │   │   ├── label_smoothing_factor
│           │   │   ├── layer_norm_eps
│           │   │   ├── length_penalty
│           │   │   ├── liger_kernel_config
│           │   │   ├── load_best_model_at_end
│           │   │   ├── local_rank
│           │   │   ├── log_level
│           │   │   ├── log_level_replica
│           │   │   ├── log_on_each_node
│           │   │   ├── logging_dir
│           │   │   ├── logging_first_step
│           │   │   ├── logging_nan_inf_filter
│           │   │   ├── logging_steps
│           │   │   ├── logging_strategy
│           │   │   ├── logit_adjustment_tau
│           │   │   ├── lr
│           │   │   ├── lr_scheduler_kwargs
│           │   │   ├── lr_scheduler_type
│           │   │   ├── max_grad_norm_req
│           │   │   ├── max_len
│           │   │   ├── max_length
│           │   │   ├── max_position_embeddings
│           │   │   ├── max_steps
│           │   │   ├── metric_for_best_model
│           │   │   ├── min_length
│           │   │   ├── model_name
│           │   │   ├── model_type
│           │   │   ├── neftune_noise_alpha
│           │   │   ├── net_structure_type
│           │   │   ├── no_cuda
│           │   │   ├── no_repeat_ngram_size
│           │   │   ├── num_attention_heads
│           │   │   ├── num_beam_groups
│           │   │   ├── num_beams
│           │   │   ├── num_hidden_groups
│           │   │   ├── num_hidden_layers
│           │   │   ├── num_labels_inferred
│           │   │   ├── num_labels_yaml
│           │   │   ├── num_memory_blocks
│           │   │   ├── num_return_sequences
│           │   │   ├── optim
│           │   │   ├── optim_target_modules
│           │   │   ├── output_hidden_states
│           │   │   ├── output_scores
│           │   │   ├── pad_token_id
│           │   │   ├── parallelism_config
│           │   │   ├── past_index
│           │   │   ├── patience
│           │   │   ├── prefix
│           │   │   ├── problem_type
│           │   │   ├── pruned_heads
│           │   │   ├── rating_col_req
│           │   │   ├── remove_invalid_values
│           │   │   ├── remove_unused_columns
│           │   │   ├── repetition_penalty
│           │   │   ├── requested_bf16
│           │   │   ├── requested_fp16
│           │   │   ├── requested_gradient_checkpointing
│           │   │   ├── requested_logging_steps
│           │   │   ├── requested_logging_strategy
│           │   │   ├── requested_save_total_limit
│           │   │   ├── requested_torch_compile
│           │   │   ├── requested_torch_compile_backend
│           │   │   ├── requested_torch_compile_mode
│           │   │   ├── restore_callback_states_from_checkpoint
│           │   │   ├── resume_from_last
│           │   │   ├── return_dict
│           │   │   ├── return_dict_in_generate
│           │   │   ├── run_name
│           │   │   ├── save_on_each_node
│           │   │   ├── save_only_model
│           │   │   ├── save_safetensors
│           │   │   ├── save_steps
│           │   │   ├── save_strategy
│           │   │   ├── save_total_limit
│           │   │   ├── seed
│           │   │   ├── sep_token_id
│           │   │   ├── suppress_tokens
│           │   │   ├── task_specific_params
│           │   │   ├── temperature
│           │   │   ├── text_col_req
│           │   │   ├── tf32
│           │   │   ├── tf_legacy_loss
│           │   │   ├── tie_encoder_decoder
│           │   │   ├── tie_word_embeddings
│           │   │   ├── tokenizer_class
│           │   │   ├── top_k
│           │   │   ├── top_p
│           │   │   ├── torchscript
│           │   │   ├── tpu_metrics_debug
│           │   │   ├── tpu_num_cores
│           │   │   ├── transformers_version
│           │   │   ├── type_vocab_size
│           │   │   ├── typical_p
│           │   │   ├── use_bfloat16
│           │   │   ├── use_cpu
│           │   │   ├── use_ipex
│           │   │   ├── use_liger_kernel
│           │   │   ├── use_mps_device
│           │   │   ├── vocab_size
│           │   │   ├── warmup_ratio
│           │   │   ├── warmup_steps
│           │   │   └── weight_decay
│           │   └── tags/
│           │       ├── mlflow.source.git.commit
│           │       ├── mlflow.source.name
│           │       ├── mlflow.source.type
│           │       └── mlflow.user
│           ├── m-5d670ee352f54f15994f88f1dd2ebaf2/
│           │   ├── artifacts/
│           │   │   ├── LICENSE.txt
│           │   │   ├── MLmodel
│           │   │   ├── components/
│           │   │   ├── conda.yaml
│           │   │   ├── model/
│           │   │   ├── model_card.md
│           │   │   ├── model_card_data.yaml
│           │   │   ├── python_env.yaml
│           │   │   └── requirements.txt
│           │   ├── meta.yaml
│           │   ├── metrics/
│           │   │   ├── val_accuracy
│           │   │   ├── val_f1_macro
│           │   │   ├── val_loss
│           │   │   ├── val_precision_macro
│           │   │   └── val_recall_macro
│           │   ├── params/
│           │   │   ├── _name_or_path
│           │   │   ├── accelerator_config
│           │   │   ├── add_cross_attention
│           │   │   ├── architectures
│           │   │   ├── attention_probs_dropout_prob
│           │   │   ├── average_tokens_across_devices
│           │   │   ├── bad_words_ids
│           │   │   ├── batch
│           │   │   ├── batch_eval_metrics
│           │   │   ├── begin_suppress_tokens
│           │   │   ├── bf16
│           │   │   ├── bf16_full_eval
│           │   │   ├── bos_token_id
│           │   │   ├── chunk_size_feed_forward
│           │   │   ├── classifier_dropout_prob
│           │   │   ├── cross_attention_hidden_size
│           │   │   ├── cw_alpha
│           │   │   ├── cw_mode
│           │   │   ├── data_seed
│           │   │   ├── dataloader_drop_last
│           │   │   ├── dataloader_num_workers
│           │   │   ├── dataloader_prefetch_factor
│           │   │   ├── ddp_backend
│           │   │   ├── debug
│           │   │   ├── decoder_start_token_id
│           │   │   ├── deepspeed
│           │   │   ├── disable_tqdm
│           │   │   ├── diversity_penalty
│           │   │   ├── do_sample
│           │   │   ├── down_scale_factor
│           │   │   ├── dtype
│           │   │   ├── early_stopping
│           │   │   ├── effective_eval_strategy
│           │   │   ├── effective_load_best_model_at_end
│           │   │   ├── effective_save_strategy
│           │   │   ├── effective_torch_compile
│           │   │   ├── effective_torch_compile_backend
│           │   │   ├── effective_torch_compile_mode
│           │   │   ├── embedding_size
│           │   │   ├── enable_logit_adjustment
│           │   │   ├── encoder_no_repeat_ngram_size
│           │   │   ├── eos_token_id
│           │   │   ├── epochs
│           │   │   ├── eval_batch
│           │   │   ├── eval_on_start
│           │   │   ├── eval_steps
│           │   │   ├── eval_use_gather_object
│           │   │   ├── exponential_decay_length_penalty
│           │   │   ├── finetuning_task
│           │   │   ├── focal_enable
│           │   │   ├── focal_gamma
│           │   │   ├── forced_bos_token_id
│           │   │   ├── forced_eos_token_id
│           │   │   ├── fp16
│           │   │   ├── fp16_full_eval
│           │   │   ├── fp16_opt_level
│           │   │   ├── fsdp
│           │   │   ├── fsdp_config
│           │   │   ├── fsdp_min_num_params
│           │   │   ├── fsdp_transformer_layer_cls_to_wrap
│           │   │   ├── gap_size
│           │   │   ├── grad_accum
│           │   │   ├── greater_is_better
│           │   │   ├── half_precision_backend
│           │   │   ├── hidden_act
│           │   │   ├── hidden_dropout_prob
│           │   │   ├── hidden_size
│           │   │   ├── id2label
│           │   │   ├── ignore_data_skip
│           │   │   ├── include_num_input_tokens_seen
│           │   │   ├── initializer_range
│           │   │   ├── inner_group_num
│           │   │   ├── intermediate_size
│           │   │   ├── is_decoder
│           │   │   ├── is_encoder_decoder
│           │   │   ├── jit_mode_eval
│           │   │   ├── label2id
│           │   │   ├── label_col_req
│           │   │   ├── label_names
│           │   │   ├── label_smoothing_factor
│           │   │   ├── layer_norm_eps
│           │   │   ├── length_penalty
│           │   │   ├── liger_kernel_config
│           │   │   ├── load_best_model_at_end
│           │   │   ├── local_rank
│           │   │   ├── log_level
│           │   │   ├── log_level_replica
│           │   │   ├── log_on_each_node
│           │   │   ├── logging_dir
│           │   │   ├── logging_first_step
│           │   │   ├── logging_nan_inf_filter
│           │   │   ├── logging_steps
│           │   │   ├── logging_strategy
│           │   │   ├── logit_adjustment_tau
│           │   │   ├── lr
│           │   │   ├── lr_scheduler_kwargs
│           │   │   ├── lr_scheduler_type
│           │   │   ├── max_grad_norm_req
│           │   │   ├── max_len
│           │   │   ├── max_length
│           │   │   ├── max_position_embeddings
│           │   │   ├── max_steps
│           │   │   ├── metric_for_best_model
│           │   │   ├── min_length
│           │   │   ├── model_name
│           │   │   ├── model_type
│           │   │   ├── neftune_noise_alpha
│           │   │   ├── net_structure_type
│           │   │   ├── no_cuda
│           │   │   ├── no_repeat_ngram_size
│           │   │   ├── num_attention_heads
│           │   │   ├── num_beam_groups
│           │   │   ├── num_beams
│           │   │   ├── num_hidden_groups
│           │   │   ├── num_hidden_layers
│           │   │   ├── num_labels_inferred
│           │   │   ├── num_labels_yaml
│           │   │   ├── num_memory_blocks
│           │   │   ├── num_return_sequences
│           │   │   ├── optim
│           │   │   ├── optim_target_modules
│           │   │   ├── output_hidden_states
│           │   │   ├── output_scores
│           │   │   ├── pad_token_id
│           │   │   ├── parallelism_config
│           │   │   ├── past_index
│           │   │   ├── patience
│           │   │   ├── prefix
│           │   │   ├── problem_type
│           │   │   ├── pruned_heads
│           │   │   ├── rating_col_req
│           │   │   ├── remove_invalid_values
│           │   │   ├── remove_unused_columns
│           │   │   ├── repetition_penalty
│           │   │   ├── requested_bf16
│           │   │   ├── requested_fp16
│           │   │   ├── requested_gradient_checkpointing
│           │   │   ├── requested_logging_steps
│           │   │   ├── requested_logging_strategy
│           │   │   ├── requested_save_total_limit
│           │   │   ├── requested_torch_compile
│           │   │   ├── requested_torch_compile_backend
│           │   │   ├── requested_torch_compile_mode
│           │   │   ├── restore_callback_states_from_checkpoint
│           │   │   ├── resume_from_last
│           │   │   ├── return_dict
│           │   │   ├── return_dict_in_generate
│           │   │   ├── run_name
│           │   │   ├── save_on_each_node
│           │   │   ├── save_only_model
│           │   │   ├── save_safetensors
│           │   │   ├── save_steps
│           │   │   ├── save_strategy
│           │   │   ├── save_total_limit
│           │   │   ├── seed
│           │   │   ├── sep_token_id
│           │   │   ├── suppress_tokens
│           │   │   ├── task_specific_params
│           │   │   ├── temperature
│           │   │   ├── text_col_req
│           │   │   ├── tf32
│           │   │   ├── tf_legacy_loss
│           │   │   ├── tie_encoder_decoder
│           │   │   ├── tie_word_embeddings
│           │   │   ├── tokenizer_class
│           │   │   ├── top_k
│           │   │   ├── top_p
│           │   │   ├── torchscript
│           │   │   ├── tpu_metrics_debug
│           │   │   ├── tpu_num_cores
│           │   │   ├── transformers_version
│           │   │   ├── type_vocab_size
│           │   │   ├── typical_p
│           │   │   ├── use_bfloat16
│           │   │   ├── use_cpu
│           │   │   ├── use_ipex
│           │   │   ├── use_liger_kernel
│           │   │   ├── use_mps_device
│           │   │   ├── vocab_size
│           │   │   ├── warmup_ratio
│           │   │   ├── warmup_steps
│           │   │   └── weight_decay
│           │   └── tags/
│           │       ├── mlflow.source.git.commit
│           │       ├── mlflow.source.name
│           │       ├── mlflow.source.type
│           │       └── mlflow.user
│           ├── m-9401c2ce4e7444a0aec3e6f6f40e13da/
│           │   ├── artifacts/
│           │   │   ├── LICENSE.txt
│           │   │   ├── MLmodel
│           │   │   ├── components/
│           │   │   ├── conda.yaml
│           │   │   ├── model/
│           │   │   ├── model_card.md
│           │   │   ├── model_card_data.yaml
│           │   │   ├── python_env.yaml
│           │   │   └── requirements.txt
│           │   ├── meta.yaml
│           │   ├── metrics/
│           │   │   ├── val_accuracy
│           │   │   ├── val_f1_macro
│           │   │   ├── val_loss
│           │   │   ├── val_precision_macro
│           │   │   └── val_recall_macro
│           │   ├── params/
│           │   │   ├── _name_or_path
│           │   │   ├── accelerator_config
│           │   │   ├── add_cross_attention
│           │   │   ├── architectures
│           │   │   ├── attention_probs_dropout_prob
│           │   │   ├── average_tokens_across_devices
│           │   │   ├── bad_words_ids
│           │   │   ├── batch
│           │   │   ├── batch_eval_metrics
│           │   │   ├── begin_suppress_tokens
│           │   │   ├── bf16
│           │   │   ├── bf16_full_eval
│           │   │   ├── bos_token_id
│           │   │   ├── chunk_size_feed_forward
│           │   │   ├── classifier_dropout_prob
│           │   │   ├── cross_attention_hidden_size
│           │   │   ├── cw_alpha
│           │   │   ├── cw_mode
│           │   │   ├── data_seed
│           │   │   ├── dataloader_drop_last
│           │   │   ├── dataloader_num_workers
│           │   │   ├── dataloader_prefetch_factor
│           │   │   ├── ddp_backend
│           │   │   ├── debug
│           │   │   ├── decoder_start_token_id
│           │   │   ├── deepspeed
│           │   │   ├── disable_tqdm
│           │   │   ├── diversity_penalty
│           │   │   ├── do_sample
│           │   │   ├── down_scale_factor
│           │   │   ├── dtype
│           │   │   ├── early_stopping
│           │   │   ├── effective_eval_strategy
│           │   │   ├── effective_load_best_model_at_end
│           │   │   ├── effective_save_strategy
│           │   │   ├── effective_torch_compile
│           │   │   ├── effective_torch_compile_backend
│           │   │   ├── effective_torch_compile_mode
│           │   │   ├── embedding_size
│           │   │   ├── enable_logit_adjustment
│           │   │   ├── encoder_no_repeat_ngram_size
│           │   │   ├── eos_token_id
│           │   │   ├── epochs
│           │   │   ├── eval_batch
│           │   │   ├── eval_on_start
│           │   │   ├── eval_steps
│           │   │   ├── eval_use_gather_object
│           │   │   ├── exponential_decay_length_penalty
│           │   │   ├── finetuning_task
│           │   │   ├── focal_enable
│           │   │   ├── focal_gamma
│           │   │   ├── forced_bos_token_id
│           │   │   ├── forced_eos_token_id
│           │   │   ├── fp16
│           │   │   ├── fp16_full_eval
│           │   │   ├── fp16_opt_level
│           │   │   ├── fsdp
│           │   │   ├── fsdp_config
│           │   │   ├── fsdp_min_num_params
│           │   │   ├── fsdp_transformer_layer_cls_to_wrap
│           │   │   ├── gap_size
│           │   │   ├── grad_accum
│           │   │   ├── greater_is_better
│           │   │   ├── half_precision_backend
│           │   │   ├── hidden_act
│           │   │   ├── hidden_dropout_prob
│           │   │   ├── hidden_size
│           │   │   ├── id2label
│           │   │   ├── ignore_data_skip
│           │   │   ├── include_num_input_tokens_seen
│           │   │   ├── initializer_range
│           │   │   ├── inner_group_num
│           │   │   ├── intermediate_size
│           │   │   ├── is_decoder
│           │   │   ├── is_encoder_decoder
│           │   │   ├── jit_mode_eval
│           │   │   ├── label2id
│           │   │   ├── label_col_req
│           │   │   ├── label_names
│           │   │   ├── label_smoothing_factor
│           │   │   ├── layer_norm_eps
│           │   │   ├── length_penalty
│           │   │   ├── liger_kernel_config
│           │   │   ├── load_best_model_at_end
│           │   │   ├── local_rank
│           │   │   ├── log_level
│           │   │   ├── log_level_replica
│           │   │   ├── log_on_each_node
│           │   │   ├── logging_dir
│           │   │   ├── logging_first_step
│           │   │   ├── logging_nan_inf_filter
│           │   │   ├── logging_steps
│           │   │   ├── logging_strategy
│           │   │   ├── logit_adjustment_tau
│           │   │   ├── lr
│           │   │   ├── lr_scheduler_kwargs
│           │   │   ├── lr_scheduler_type
│           │   │   ├── max_grad_norm_req
│           │   │   ├── max_len
│           │   │   ├── max_length
│           │   │   ├── max_position_embeddings
│           │   │   ├── max_steps
│           │   │   ├── metric_for_best_model
│           │   │   ├── min_length
│           │   │   ├── model_name
│           │   │   ├── model_type
│           │   │   ├── neftune_noise_alpha
│           │   │   ├── net_structure_type
│           │   │   ├── no_cuda
│           │   │   ├── no_repeat_ngram_size
│           │   │   ├── num_attention_heads
│           │   │   ├── num_beam_groups
│           │   │   ├── num_beams
│           │   │   ├── num_hidden_groups
│           │   │   ├── num_hidden_layers
│           │   │   ├── num_labels_inferred
│           │   │   ├── num_labels_yaml
│           │   │   ├── num_memory_blocks
│           │   │   ├── num_return_sequences
│           │   │   ├── optim
│           │   │   ├── optim_target_modules
│           │   │   ├── output_hidden_states
│           │   │   ├── output_scores
│           │   │   ├── pad_token_id
│           │   │   ├── parallelism_config
│           │   │   ├── past_index
│           │   │   ├── patience
│           │   │   ├── prefix
│           │   │   ├── problem_type
│           │   │   ├── pruned_heads
│           │   │   ├── rating_col_req
│           │   │   ├── remove_invalid_values
│           │   │   ├── remove_unused_columns
│           │   │   ├── repetition_penalty
│           │   │   ├── requested_bf16
│           │   │   ├── requested_fp16
│           │   │   ├── requested_gradient_checkpointing
│           │   │   ├── requested_logging_steps
│           │   │   ├── requested_logging_strategy
│           │   │   ├── requested_save_total_limit
│           │   │   ├── requested_torch_compile
│           │   │   ├── requested_torch_compile_backend
│           │   │   ├── requested_torch_compile_mode
│           │   │   ├── restore_callback_states_from_checkpoint
│           │   │   ├── resume_from_last
│           │   │   ├── return_dict
│           │   │   ├── return_dict_in_generate
│           │   │   ├── run_name
│           │   │   ├── save_on_each_node
│           │   │   ├── save_only_model
│           │   │   ├── save_safetensors
│           │   │   ├── save_steps
│           │   │   ├── save_strategy
│           │   │   ├── save_total_limit
│           │   │   ├── seed
│           │   │   ├── sep_token_id
│           │   │   ├── suppress_tokens
│           │   │   ├── task_specific_params
│           │   │   ├── temperature
│           │   │   ├── text_col_req
│           │   │   ├── tf32
│           │   │   ├── tf_legacy_loss
│           │   │   ├── tie_encoder_decoder
│           │   │   ├── tie_word_embeddings
│           │   │   ├── tokenizer_class
│           │   │   ├── top_k
│           │   │   ├── top_p
│           │   │   ├── torchscript
│           │   │   ├── tpu_metrics_debug
│           │   │   ├── tpu_num_cores
│           │   │   ├── transformers_version
│           │   │   ├── type_vocab_size
│           │   │   ├── typical_p
│           │   │   ├── use_bfloat16
│           │   │   ├── use_cpu
│           │   │   ├── use_ipex
│           │   │   ├── use_liger_kernel
│           │   │   ├── use_mps_device
│           │   │   ├── vocab_size
│           │   │   ├── warmup_ratio
│           │   │   ├── warmup_steps
│           │   │   └── weight_decay
│           │   └── tags/
│           │       ├── mlflow.source.git.commit
│           │       ├── mlflow.source.name
│           │       ├── mlflow.source.type
│           │       └── mlflow.user
│           ├── m-bc9dd1e55d8c42f1adc8333799f60238/
│           │   ├── artifacts/
│           │   │   ├── LICENSE.txt
│           │   │   ├── MLmodel
│           │   │   ├── components/
│           │   │   ├── conda.yaml
│           │   │   ├── model/
│           │   │   ├── model_card.md
│           │   │   ├── model_card_data.yaml
│           │   │   ├── python_env.yaml
│           │   │   └── requirements.txt
│           │   ├── meta.yaml
│           │   ├── metrics/
│           │   │   ├── val_accuracy
│           │   │   ├── val_f1_macro
│           │   │   ├── val_loss
│           │   │   ├── val_precision_macro
│           │   │   └── val_recall_macro
│           │   ├── params/
│           │   │   ├── _name_or_path
│           │   │   ├── accelerator_config
│           │   │   ├── add_cross_attention
│           │   │   ├── architectures
│           │   │   ├── attention_probs_dropout_prob
│           │   │   ├── average_tokens_across_devices
│           │   │   ├── bad_words_ids
│           │   │   ├── batch
│           │   │   ├── batch_eval_metrics
│           │   │   ├── begin_suppress_tokens
│           │   │   ├── bf16
│           │   │   ├── bf16_full_eval
│           │   │   ├── bos_token_id
│           │   │   ├── chunk_size_feed_forward
│           │   │   ├── classifier_dropout_prob
│           │   │   ├── cross_attention_hidden_size
│           │   │   ├── cw_alpha
│           │   │   ├── cw_mode
│           │   │   ├── data_seed
│           │   │   ├── dataloader_drop_last
│           │   │   ├── dataloader_num_workers
│           │   │   ├── dataloader_prefetch_factor
│           │   │   ├── ddp_backend
│           │   │   ├── debug
│           │   │   ├── decoder_start_token_id
│           │   │   ├── deepspeed
│           │   │   ├── disable_tqdm
│           │   │   ├── diversity_penalty
│           │   │   ├── do_sample
│           │   │   ├── down_scale_factor
│           │   │   ├── dtype
│           │   │   ├── early_stopping
│           │   │   ├── effective_eval_strategy
│           │   │   ├── effective_load_best_model_at_end
│           │   │   ├── effective_save_strategy
│           │   │   ├── effective_torch_compile
│           │   │   ├── effective_torch_compile_backend
│           │   │   ├── effective_torch_compile_mode
│           │   │   ├── embedding_size
│           │   │   ├── enable_logit_adjustment
│           │   │   ├── encoder_no_repeat_ngram_size
│           │   │   ├── eos_token_id
│           │   │   ├── epochs
│           │   │   ├── eval_batch
│           │   │   ├── eval_on_start
│           │   │   ├── eval_steps
│           │   │   ├── eval_use_gather_object
│           │   │   ├── exponential_decay_length_penalty
│           │   │   ├── finetuning_task
│           │   │   ├── focal_enable
│           │   │   ├── focal_gamma
│           │   │   ├── forced_bos_token_id
│           │   │   ├── forced_eos_token_id
│           │   │   ├── fp16
│           │   │   ├── fp16_full_eval
│           │   │   ├── fp16_opt_level
│           │   │   ├── fsdp
│           │   │   ├── fsdp_config
│           │   │   ├── fsdp_min_num_params
│           │   │   ├── fsdp_transformer_layer_cls_to_wrap
│           │   │   ├── gap_size
│           │   │   ├── grad_accum
│           │   │   ├── greater_is_better
│           │   │   ├── half_precision_backend
│           │   │   ├── hidden_act
│           │   │   ├── hidden_dropout_prob
│           │   │   ├── hidden_size
│           │   │   ├── id2label
│           │   │   ├── ignore_data_skip
│           │   │   ├── include_num_input_tokens_seen
│           │   │   ├── initializer_range
│           │   │   ├── inner_group_num
│           │   │   ├── intermediate_size
│           │   │   ├── is_decoder
│           │   │   ├── is_encoder_decoder
│           │   │   ├── jit_mode_eval
│           │   │   ├── label2id
│           │   │   ├── label_col_req
│           │   │   ├── label_names
│           │   │   ├── label_smoothing_factor
│           │   │   ├── layer_norm_eps
│           │   │   ├── length_penalty
│           │   │   ├── liger_kernel_config
│           │   │   ├── load_best_model_at_end
│           │   │   ├── local_rank
│           │   │   ├── log_level
│           │   │   ├── log_level_replica
│           │   │   ├── log_on_each_node
│           │   │   ├── logging_dir
│           │   │   ├── logging_first_step
│           │   │   ├── logging_nan_inf_filter
│           │   │   ├── logging_steps
│           │   │   ├── logging_strategy
│           │   │   ├── logit_adjustment_tau
│           │   │   ├── lr
│           │   │   ├── lr_scheduler_kwargs
│           │   │   ├── lr_scheduler_type
│           │   │   ├── max_grad_norm_req
│           │   │   ├── max_len
│           │   │   ├── max_length
│           │   │   ├── max_position_embeddings
│           │   │   ├── max_steps
│           │   │   ├── metric_for_best_model
│           │   │   ├── min_length
│           │   │   ├── model_name
│           │   │   ├── model_type
│           │   │   ├── neftune_noise_alpha
│           │   │   ├── net_structure_type
│           │   │   ├── no_cuda
│           │   │   ├── no_repeat_ngram_size
│           │   │   ├── num_attention_heads
│           │   │   ├── num_beam_groups
│           │   │   ├── num_beams
│           │   │   ├── num_hidden_groups
│           │   │   ├── num_hidden_layers
│           │   │   ├── num_labels_inferred
│           │   │   ├── num_labels_yaml
│           │   │   ├── num_memory_blocks
│           │   │   ├── num_return_sequences
│           │   │   ├── optim
│           │   │   ├── optim_target_modules
│           │   │   ├── output_hidden_states
│           │   │   ├── output_scores
│           │   │   ├── pad_token_id
│           │   │   ├── parallelism_config
│           │   │   ├── past_index
│           │   │   ├── patience
│           │   │   ├── prefix
│           │   │   ├── problem_type
│           │   │   ├── pruned_heads
│           │   │   ├── rating_col_req
│           │   │   ├── remove_invalid_values
│           │   │   ├── remove_unused_columns
│           │   │   ├── repetition_penalty
│           │   │   ├── requested_bf16
│           │   │   ├── requested_fp16
│           │   │   ├── requested_gradient_checkpointing
│           │   │   ├── requested_logging_steps
│           │   │   ├── requested_logging_strategy
│           │   │   ├── requested_save_total_limit
│           │   │   ├── requested_torch_compile
│           │   │   ├── requested_torch_compile_backend
│           │   │   ├── requested_torch_compile_mode
│           │   │   ├── restore_callback_states_from_checkpoint
│           │   │   ├── resume_from_last
│           │   │   ├── return_dict
│           │   │   ├── return_dict_in_generate
│           │   │   ├── run_name
│           │   │   ├── save_on_each_node
│           │   │   ├── save_only_model
│           │   │   ├── save_safetensors
│           │   │   ├── save_steps
│           │   │   ├── save_strategy
│           │   │   ├── save_total_limit
│           │   │   ├── seed
│           │   │   ├── sep_token_id
│           │   │   ├── suppress_tokens
│           │   │   ├── task_specific_params
│           │   │   ├── temperature
│           │   │   ├── text_col_req
│           │   │   ├── tf32
│           │   │   ├── tf_legacy_loss
│           │   │   ├── tie_encoder_decoder
│           │   │   ├── tie_word_embeddings
│           │   │   ├── tokenizer_class
│           │   │   ├── top_k
│           │   │   ├── top_p
│           │   │   ├── torchscript
│           │   │   ├── tpu_metrics_debug
│           │   │   ├── tpu_num_cores
│           │   │   ├── transformers_version
│           │   │   ├── type_vocab_size
│           │   │   ├── typical_p
│           │   │   ├── use_bfloat16
│           │   │   ├── use_cpu
│           │   │   ├── use_ipex
│           │   │   ├── use_liger_kernel
│           │   │   ├── use_mps_device
│           │   │   ├── vocab_size
│           │   │   ├── warmup_ratio
│           │   │   ├── warmup_steps
│           │   │   └── weight_decay
│           │   └── tags/
│           │       ├── mlflow.source.git.commit
│           │       ├── mlflow.source.name
│           │       ├── mlflow.source.type
│           │       └── mlflow.user
│           └── m-dd0122f77cb54c0ba5ee9851f0967301/
│               ├── artifacts/
│               │   ├── LICENSE.txt
│               │   ├── MLmodel
│               │   ├── components/
│               │   ├── conda.yaml
│               │   ├── model/
│               │   ├── model_card.md
│               │   ├── model_card_data.yaml
│               │   ├── python_env.yaml
│               │   └── requirements.txt
│               ├── meta.yaml
│               ├── metrics/
│               │   ├── val_accuracy
│               │   ├── val_f1_macro
│               │   ├── val_loss
│               │   ├── val_precision_macro
│               │   └── val_recall_macro
│               ├── params/
│               │   ├── _name_or_path
│               │   ├── accelerator_config
│               │   ├── add_cross_attention
│               │   ├── architectures
│               │   ├── attention_probs_dropout_prob
│               │   ├── average_tokens_across_devices
│               │   ├── bad_words_ids
│               │   ├── batch
│               │   ├── batch_eval_metrics
│               │   ├── begin_suppress_tokens
│               │   ├── bf16
│               │   ├── bf16_full_eval
│               │   ├── bos_token_id
│               │   ├── chunk_size_feed_forward
│               │   ├── classifier_dropout_prob
│               │   ├── cross_attention_hidden_size
│               │   ├── cw_alpha
│               │   ├── cw_mode
│               │   ├── data_seed
│               │   ├── dataloader_drop_last
│               │   ├── dataloader_num_workers
│               │   ├── dataloader_prefetch_factor
│               │   ├── ddp_backend
│               │   ├── debug
│               │   ├── decoder_start_token_id
│               │   ├── deepspeed
│               │   ├── disable_tqdm
│               │   ├── diversity_penalty
│               │   ├── do_sample
│               │   ├── down_scale_factor
│               │   ├── dtype
│               │   ├── early_stopping
│               │   ├── effective_eval_strategy
│               │   ├── effective_load_best_model_at_end
│               │   ├── effective_save_strategy
│               │   ├── effective_torch_compile
│               │   ├── effective_torch_compile_backend
│               │   ├── effective_torch_compile_mode
│               │   ├── embedding_size
│               │   ├── enable_logit_adjustment
│               │   ├── encoder_no_repeat_ngram_size
│               │   ├── eos_token_id
│               │   ├── epochs
│               │   ├── eval_batch
│               │   ├── eval_on_start
│               │   ├── eval_steps
│               │   ├── eval_use_gather_object
│               │   ├── exponential_decay_length_penalty
│               │   ├── finetuning_task
│               │   ├── focal_enable
│               │   ├── focal_gamma
│               │   ├── forced_bos_token_id
│               │   ├── forced_eos_token_id
│               │   ├── fp16
│               │   ├── fp16_full_eval
│               │   ├── fp16_opt_level
│               │   ├── fsdp
│               │   ├── fsdp_config
│               │   ├── fsdp_min_num_params
│               │   ├── fsdp_transformer_layer_cls_to_wrap
│               │   ├── gap_size
│               │   ├── grad_accum
│               │   ├── greater_is_better
│               │   ├── half_precision_backend
│               │   ├── hidden_act
│               │   ├── hidden_dropout_prob
│               │   ├── hidden_size
│               │   ├── id2label
│               │   ├── ignore_data_skip
│               │   ├── include_num_input_tokens_seen
│               │   ├── initializer_range
│               │   ├── inner_group_num
│               │   ├── intermediate_size
│               │   ├── is_decoder
│               │   ├── is_encoder_decoder
│               │   ├── jit_mode_eval
│               │   ├── label2id
│               │   ├── label_col_req
│               │   ├── label_names
│               │   ├── label_smoothing_factor
│               │   ├── layer_norm_eps
│               │   ├── length_penalty
│               │   ├── liger_kernel_config
│               │   ├── load_best_model_at_end
│               │   ├── local_rank
│               │   ├── log_level
│               │   ├── log_level_replica
│               │   ├── log_on_each_node
│               │   ├── logging_dir
│               │   ├── logging_first_step
│               │   ├── logging_nan_inf_filter
│               │   ├── logging_steps
│               │   ├── logging_strategy
│               │   ├── logit_adjustment_tau
│               │   ├── lr
│               │   ├── lr_scheduler_kwargs
│               │   ├── lr_scheduler_type
│               │   ├── max_grad_norm_req
│               │   ├── max_len
│               │   ├── max_length
│               │   ├── max_position_embeddings
│               │   ├── max_steps
│               │   ├── metric_for_best_model
│               │   ├── min_length
│               │   ├── model_name
│               │   ├── model_type
│               │   ├── neftune_noise_alpha
│               │   ├── net_structure_type
│               │   ├── no_cuda
│               │   ├── no_repeat_ngram_size
│               │   ├── num_attention_heads
│               │   ├── num_beam_groups
│               │   ├── num_beams
│               │   ├── num_hidden_groups
│               │   ├── num_hidden_layers
│               │   ├── num_labels_inferred
│               │   ├── num_labels_yaml
│               │   ├── num_memory_blocks
│               │   ├── num_return_sequences
│               │   ├── optim
│               │   ├── optim_target_modules
│               │   ├── output_hidden_states
│               │   ├── output_scores
│               │   ├── pad_token_id
│               │   ├── parallelism_config
│               │   ├── past_index
│               │   ├── patience
│               │   ├── prefix
│               │   ├── problem_type
│               │   ├── pruned_heads
│               │   ├── rating_col_req
│               │   ├── remove_invalid_values
│               │   ├── remove_unused_columns
│               │   ├── repetition_penalty
│               │   ├── requested_bf16
│               │   ├── requested_fp16
│               │   ├── requested_gradient_checkpointing
│               │   ├── requested_logging_steps
│               │   ├── requested_logging_strategy
│               │   ├── requested_save_total_limit
│               │   ├── requested_torch_compile
│               │   ├── requested_torch_compile_backend
│               │   ├── requested_torch_compile_mode
│               │   ├── restore_callback_states_from_checkpoint
│               │   ├── resume_from_last
│               │   ├── return_dict
│               │   ├── return_dict_in_generate
│               │   ├── run_name
│               │   ├── save_on_each_node
│               │   ├── save_only_model
│               │   ├── save_safetensors
│               │   ├── save_steps
│               │   ├── save_strategy
│               │   ├── save_total_limit
│               │   ├── seed
│               │   ├── sep_token_id
│               │   ├── suppress_tokens
│               │   ├── task_specific_params
│               │   ├── temperature
│               │   ├── text_col_req
│               │   ├── tf32
│               │   ├── tf_legacy_loss
│               │   ├── tie_encoder_decoder
│               │   ├── tie_word_embeddings
│               │   ├── tokenizer_class
│               │   ├── top_k
│               │   ├── top_p
│               │   ├── torchscript
│               │   ├── tpu_metrics_debug
│               │   ├── tpu_num_cores
│               │   ├── transformers_version
│               │   ├── type_vocab_size
│               │   ├── typical_p
│               │   ├── use_bfloat16
│               │   ├── use_cpu
│               │   ├── use_ipex
│               │   ├── use_liger_kernel
│               │   ├── use_mps_device
│               │   ├── vocab_size
│               │   ├── warmup_ratio
│               │   ├── warmup_steps
│               │   └── weight_decay
│               └── tags/
│                   ├── mlflow.source.git.commit
│                   ├── mlflow.source.name
│                   ├── mlflow.source.type
│                   └── mlflow.user
├── models/
│   ├── albert_sample_30pct/
│   │   ├── config.json
│   │   ├── model.safetensors
│   │   ├── params_snapshot.json
│   │   ├── special_tokens_map.json
│   │   ├── spiece.model
│   │   ├── tokenizer.json
│   │   ├── tokenizer_config.json
│   │   └── train_meta.json
│   ├── ate_roberta_base/
│   │   ├── checkpoint-9000/
│   │   │   ├── config.json
│   │   │   ├── merges.txt
│   │   │   ├── model.safetensors
│   │   │   ├── optimizer.pt
│   │   │   ├── rng_state.pth
│   │   │   ├── scheduler.pt
│   │   │   ├── special_tokens_map.json
│   │   │   ├── tokenizer.json
│   │   │   ├── tokenizer_config.json
│   │   │   ├── trainer_state.json
│   │   │   ├── training_args.bin
│   │   │   └── vocab.json
│   │   ├── config.json
│   │   ├── merges.txt
│   │   ├── model.safetensors
│   │   ├── special_tokens_map.json
│   │   ├── tokenizer.json
│   │   ├── tokenizer_config.json
│   │   ├── training_args.bin
│   │   └── vocab.json
│   ├── sentiment_model_rf/
│   │   ├── modelo_random_forest.joblib.dvc
│   │   └── tfidf_vectorizer.joblib.dvc
│   └── sentiment_rf_sample/
│       ├── preprocess_config.json
│       ├── rf_model.joblib
│       └── tfidf_vectorizer.joblib
├── notebooks/
│   ├── 01_modelo_sentimiento_reviews.ipynb
│   ├── EDA_preprocessing_from_params.ipynb
│   └── reports/
│       └── eda/
│           ├── 20250908_193618/
│           │   ├── class_distribution.csv
│           │   ├── class_distribution.png
│           │   ├── duplicates_sample.csv
│           │   ├── eda_summary.json
│           │   ├── hist_len_chars.png
│           │   ├── hist_len_tokens_albert-base-v2.png
│           │   ├── hist_len_words.png
│           │   ├── lang_counts_sample.csv
│           │   ├── lang_counts_sample.png
│           │   ├── max_len_recommendation.json
│           │   ├── sample_cleaning.csv
│           │   └── split_plan_counts.csv
│           └── 20250909_202117/
│               ├── class_distribution.csv
│               ├── class_distribution.png
│               ├── duplicates_sample.csv
│               ├── eda_summary.json
│               ├── hist_len_chars.png
│               ├── hist_len_tokens_albert-base-v2.png
│               ├── hist_len_words.png
│               ├── lang_counts_sample.csv
│               ├── lang_counts_sample.png
│               ├── max_len_recommendation.json
│               ├── sample_cleaning.csv
│               └── split_plan_counts.csv
├── params.yaml
├── reports/
│   ├── absa/
│   │   ├── ate_spans.parquet
│   │   ├── ate_spans_mapped.parquet
│   │   ├── cards/
│   │   │   ├── cards_index.html
│   │   │   ├── data -> ../../../data/
│   │   │   ├── debug_radar_stats_by_category.csv
│   │   │   ├── debug_radar_stats_global.csv
│   │   │   ├── product_cards.jsonl
│   │   │   ├── product_cards_recalc.html
│   │   │   ├── product_cards_recalc_wfilters.html
│   │   │   ├── product_cards_with_images.jsonl
│   │   │   ├── product_cards_with_images.recalc.jsonl
│   │   │   └── top10_index.html
│   │   ├── final_all/
│   │   │   ├── README_ABSA.txt
│   │   │   ├── absa_final.parquet/
│   │   │   │   ├── _SUCCESS
│   │   │   │   ├── part-00000-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00001-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00002-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00003-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00004-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00005-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00006-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00007-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00008-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00009-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00010-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00011-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00012-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00013-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00014-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00015-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00016-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00017-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00018-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00019-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00020-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   ├── part-00021-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   │   └── part-00022-e077fcb4-e0e8-49a3-96b3-8f539871bf65-c000.snappy.parquet
│   │   │   ├── charts/
│   │   │   │   ├── count_by_category.png
│   │   │   │   ├── count_by_category_sentiment.png
│   │   │   │   └── count_by_sentiment.png
│   │   │   ├── eda/
│   │   │   │   ├── count_by_category/
│   │   │   │   │   ├── _SUCCESS
│   │   │   │   │   └── part-00000-6053a305-d811-4c9a-ae77-2857f3fef3d2-c000.csv
│   │   │   │   ├── count_by_category_sentiment/
│   │   │   │   │   ├── _SUCCESS
│   │   │   │   │   └── part-00000-df12c65e-34f6-4d86-983e-23e8aaf02d74-c000.csv
│   │   │   │   ├── count_by_sentiment/
│   │   │   │   │   ├── _SUCCESS
│   │   │   │   │   └── part-00000-490ee89b-d469-45bb-bbe5-d71843a67873-c000.csv
│   │   │   │   ├── coverage/
│   │   │   │   │   ├── _SUCCESS
│   │   │   │   │   └── part-00000-40c69d62-02f6-4be9-912f-ee7d7664d9cf-c000.csv
│   │   │   │   └── top_aspects/
│   │   │   │       ├── _SUCCESS
│   │   │   │       └── part-00000-5d2447f3-a082-4fb6-b7c8-38c73c331a6d-c000.csv
│   │   │   ├── logs/
│   │   │   │   ├── counts.txt
│   │   │   │   ├── sent_sample.txt
│   │   │   │   ├── sent_schema.txt
│   │   │   │   ├── spans_sample.txt
│   │   │   │   └── spans_schema.txt
│   │   │   └── preview_fused.parquet/
│   │   │       ├── _SUCCESS
│   │   │       └── part-00000-a83d5f60-ffc9-4c54-8a11-9942a1a7ef3a-c000.snappy.parquet
│   │   ├── final_report/
│   │   │   ├── global_top10.csv
│   │   │   ├── insights_charts/
│   │   │   │   ├── brand_benchmarks_by_category.html
│   │   │   │   ├── category_opportunity_matrix.html
│   │   │   │   ├── global_influence.html
│   │   │   │   ├── neg_aspect_cooccurrence_top50.html
│   │   │   │   ├── neg_top20_aspects.html
│   │   │   │   ├── neg_top20_terms.html
│   │   │   │   ├── per_category_top10_negative.html
│   │   │   │   └── per_category_top10_positive.html
│   │   │   ├── per_category_top10.csv
│   │   │   └── product_cards.jsonl
│   │   ├── images/
│   │   │   ├── host_403.txt
│   │   │   ├── host_403_counts.csv
│   │   │   ├── product_images.csv
│   │   │   └── product_thumbs.csv
│   │   ├── insights/
│   │   │   ├── brand_benchmarks_by_category.csv
│   │   │   ├── category_opportunity_matrix.csv
│   │   │   ├── charts/
│   │   │   │   ├── brand_benchmarks_by_category.html
│   │   │   │   ├── category_opportunity_matrix.html
│   │   │   │   ├── global_influence.html
│   │   │   │   ├── neg_aspect_cooccurrence_top50.html
│   │   │   │   ├── neg_top20_aspects.html
│   │   │   │   ├── neg_top20_terms.html
│   │   │   │   ├── per_category_top10_negative.html
│   │   │   │   └── per_category_top10_positive.html
│   │   │   ├── global_top50_influence.csv
│   │   │   ├── neg_aspect_cooccurrence_top50.csv
│   │   │   ├── neg_top20_aspects.csv
│   │   │   ├── neg_top20_terms.csv
│   │   │   ├── per_category_top10_negative.csv
│   │   │   └── per_category_top10_positive.csv
│   │   ├── loves_top10/
│   │   │   ├── global_top10.csv
│   │   │   └── per_category_top10.csv
│   │   ├── product_rating_stats.parquet/
│   │   │   ├── _SUCCESS
│   │   │   └── part-00000-b6d2cc58-5a2c-48a5-b4f5-62670ab593af-c000.snappy.parquet
│   │   └── top10_loves.csv
│   ├── albert_sample_30pct/
│   │   ├── ABSA_test_full_dataset/
│   │   ├── eval/
│   │   │   ├── confusion.csv
│   │   │   ├── confusion.png
│   │   │   ├── confusion_normalized.csv
│   │   │   ├── confusion_normalized.png
│   │   │   ├── metrics.json
│   │   │   └── predictions.parquet
│   │   ├── eval_rest/
│   │   │   ├── confusion.csv
│   │   │   ├── confusion.png
│   │   │   ├── confusion_normalized.csv
│   │   │   ├── confusion_normalized.png
│   │   │   ├── metrics.json
│   │   │   └── predictions.parquet
│   │   ├── infer_eval/
│   │   ├── infer_full_pandas/
│   │   │   └── predictions.parquet
│   │   ├── infer_top50_upvoted_ulta/
│   │   │   ├── pred_distribution_csv/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-d70b5598-7a40-4e03-b84a-986f7a85413d-c000.csv
│   │   │   ├── predictions.parquet/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-d14af3ab-a187-496e-b7a3-d552ddff95a7-c000.snappy.parquet
│   │   │   └── top50_reviews_csv/
│   │   │       ├── _SUCCESS
│   │   │       └── part-00000-e6ad80d6-4006-44aa-945d-f306ab06ca7f-c000.csv
│   │   └── ulta_top50/
│   │       ├── pred_distribution_csv/
│   │       │   ├── _SUCCESS
│   │       │   └── part-00000-b1916e4e-6a38-4085-ba0a-aa2dcdac9112-c000.csv
│   │       ├── predictions.parquet/
│   │       │   ├── _SUCCESS
│   │       │   └── part-00000-41e222a1-128c-4c07-9cba-06b2e4218c32-c000.snappy.parquet
│   │       └── top50_reviews_csv/
│   │           ├── _SUCCESS
│   │           └── part-00000-e217e5a1-8d72-4f52-9980-025a583d21d1-c000.csv
│   ├── deep_dive/
│   │   ├── coaspects__Caudalie__Moisturizers__fragrance.csv
│   │   ├── coaspects__Dr. Jart+__Moisturizers__texture.csv
│   │   ├── coaspects__Drunk Elephant__Moisturizers__price.csv
│   │   ├── coaspects__Drunk Elephant__Moisturizers__texture.csv
│   │   ├── coaspects__Farmacy__Moisturizers__texture.csv
│   │   ├── coaspects__LANEIGE__Lip Balms & Treatments__effectiveness.csv
│   │   ├── coaspects__SK-II__Moisturizers__price.csv
│   │   ├── coaspects__Summer Fridays__Masks__hydration.csv
│   │   ├── coaspects__Summer Fridays__Masks__texture.csv
│   │   ├── coaspects__Sunday Riley__Moisturizers__fragrance.csv
│   │   ├── coaspects__Sunday Riley__Moisturizers__texture.csv
│   │   ├── coaspects__Supergoop!__Mini Size__texture.csv
│   │   ├── coaspects__Supergoop!__Sunscreen__texture.csv
│   │   ├── coaspects__Tatcha__Moisturizers__finish.csv
│   │   ├── coaspects__Tatcha__Moisturizers__fragrance.csv
│   │   ├── coaspects__Tatcha__Moisturizers__hydration.csv
│   │   ├── coaspects__Tatcha__Moisturizers__texture.csv
│   │   ├── coaspects__The INKEY List__Cleansers__texture.csv
│   │   ├── coaspects__The Ordinary__Treatments__irritation.csv
│   │   ├── coaspects__The Ordinary__Treatments__texture.csv
│   │   ├── sample_reviews__Caudalie__Moisturizers__fragrance.csv
│   │   ├── sample_reviews__Dr. Jart+__Moisturizers__texture.csv
│   │   ├── sample_reviews__Drunk Elephant__Moisturizers__price.csv
│   │   ├── sample_reviews__Drunk Elephant__Moisturizers__texture.csv
│   │   ├── sample_reviews__Farmacy__Moisturizers__texture.csv
│   │   ├── sample_reviews__LANEIGE__Lip Balms & Treatments__effectiveness.csv
│   │   ├── sample_reviews__SK-II__Moisturizers__price.csv
│   │   ├── sample_reviews__Summer Fridays__Masks__hydration.csv
│   │   ├── sample_reviews__Summer Fridays__Masks__texture.csv
│   │   ├── sample_reviews__Sunday Riley__Moisturizers__fragrance.csv
│   │   ├── sample_reviews__Sunday Riley__Moisturizers__texture.csv
│   │   ├── sample_reviews__Supergoop!__Mini Size__texture.csv
│   │   ├── sample_reviews__Supergoop!__Sunscreen__texture.csv
│   │   ├── sample_reviews__Tatcha__Moisturizers__finish.csv
│   │   ├── sample_reviews__Tatcha__Moisturizers__fragrance.csv
│   │   ├── sample_reviews__Tatcha__Moisturizers__hydration.csv
│   │   ├── sample_reviews__Tatcha__Moisturizers__texture.csv
│   │   ├── sample_reviews__The INKEY List__Cleansers__texture.csv
│   │   ├── sample_reviews__The Ordinary__Treatments__irritation.csv
│   │   ├── sample_reviews__The Ordinary__Treatments__texture.csv
│   │   ├── terms__Caudalie__Moisturizers__fragrance.csv
│   │   ├── terms__Dr. Jart+__Moisturizers__texture.csv
│   │   ├── terms__Drunk Elephant__Moisturizers__price.csv
│   │   ├── terms__Drunk Elephant__Moisturizers__texture.csv
│   │   ├── terms__Farmacy__Moisturizers__texture.csv
│   │   ├── terms__LANEIGE__Lip Balms & Treatments__effectiveness.csv
│   │   ├── terms__SK-II__Moisturizers__price.csv
│   │   ├── terms__Summer Fridays__Masks__hydration.csv
│   │   ├── terms__Summer Fridays__Masks__texture.csv
│   │   ├── terms__Sunday Riley__Moisturizers__fragrance.csv
│   │   ├── terms__Sunday Riley__Moisturizers__texture.csv
│   │   ├── terms__Supergoop!__Mini Size__texture.csv
│   │   ├── terms__Supergoop!__Sunscreen__texture.csv
│   │   ├── terms__Tatcha__Moisturizers__finish.csv
│   │   ├── terms__Tatcha__Moisturizers__fragrance.csv
│   │   ├── terms__Tatcha__Moisturizers__hydration.csv
│   │   ├── terms__Tatcha__Moisturizers__texture.csv
│   │   ├── terms__The INKEY List__Cleansers__texture.csv
│   │   ├── terms__The Ordinary__Treatments__irritation.csv
│   │   └── terms__The Ordinary__Treatments__texture.csv
│   ├── eda/
│   │   ├── EDA_Comparativa_Full_vs_Sample30.docx
│   │   ├── compare_full_vs_30/
│   │   │   ├── A_token_lengths_albert-base-v2_clip128.png
│   │   │   ├── B_token_lengths_albert-base-v2_clip128.png
│   │   │   ├── class_counts_pivot/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-4f6bbc62-8157-495f-959e-f32dabdde8af-c000.csv
│   │   │   ├── class_distribution/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-1cce040b-8cd8-41bc-beab-e9385300ddf1-c000.csv
│   │   │   ├── class_pct_pivot/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-9d8344a0-ca23-4883-8345-0726787fd3ed-c000.csv
│   │   │   ├── head_A/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-bb582710-f99d-4573-8548-4fef2871a630-c000.csv
│   │   │   ├── head_B/
│   │   │   │   ├── _SUCCESS
│   │   │   │   └── part-00000-98adcd51-c2f0-451a-b9ac-fbb6775c6399-c000.csv
│   │   │   ├── sizes.json
│   │   │   └── token_length_stats.json
│   │   ├── full/
│   │   │   ├── dist_category.csv
│   │   │   ├── dist_sentiment.csv
│   │   │   ├── figs/
│   │   │   │   ├── dist_sentiment.png
│   │   │   │   ├── len_hist.png
│   │   │   │   ├── tokens_hist.png
│   │   │   │   └── tokens_hist_trunc512.png
│   │   │   ├── len_stats.json
│   │   │   ├── summary.json
│   │   │   ├── token_stats.json
│   │   │   └── tokens_hist.csv
│   │   └── sample_30/
│   │       ├── dist_category.csv
│   │       ├── dist_sentiment.csv
│   │       ├── figs/
│   │       │   ├── dist_sentiment.png
│   │       │   ├── len_hist.png
│   │       │   ├── tokens_hist.png
│   │       │   └── tokens_hist_trunc512.png
│   │       ├── len_stats.json
│   │       ├── summary.json
│   │       ├── token_stats.json
│   │       └── tokens_hist.csv
│   ├── evaluation/
│   │   ├── full_preview.csv
│   │   └── test_preview.csv
│   ├── figures/
│   ├── ingredients_diff/
│   │   ├── ingredients_diff__Caudalie__Moisturizers.csv
│   │   ├── ingredients_diff__Dr. Jart+__Moisturizers.csv
│   │   ├── ingredients_diff__Drunk Elephant__Moisturizers.csv
│   │   ├── ingredients_diff__Farmacy__Moisturizers.csv
│   │   ├── ingredients_diff__LANEIGE__Lip Balms & Treatments.csv
│   │   ├── ingredients_diff__SK-II__Moisturizers.csv
│   │   ├── ingredients_diff__Summer Fridays__Masks.csv
│   │   ├── ingredients_diff__Sunday Riley__Moisturizers.csv
│   │   ├── ingredients_diff__Supergoop!__Mini Size.csv
│   │   ├── ingredients_diff__Supergoop!__Sunscreen.csv
│   │   ├── ingredients_diff__Tatcha__Moisturizers.csv
│   │   ├── ingredients_diff__The INKEY List__Cleansers.csv
│   │   └── ingredients_diff__The Ordinary__Treatments.csv
│   ├── loves_top10/
│   │   ├── global_top10.csv
│   │   └── per_category_top10.csv
│   ├── sentiment_rf/
│   │   └── val_predictions.parquet
│   ├── sentiment_rf_sample/
│   │   ├── eval/
│   │   │   ├── confusion_all.png
│   │   │   ├── confusion_all_norm.png
│   │   │   ├── metrics_overall.json
│   │   │   └── test_predictions.parquet
│   │   ├── infer/
│   │   │   └── test_predictions.parquet
│   │   ├── infer_eval_full/
│   │   │   ├── confusion_all.png
│   │   │   ├── confusion_all_norm.png
│   │   │   └── metrics_overall.json
│   │   ├── reports.lnk
│   │   └── ulta_top50/
│   │       ├── pred_distribution_csv/
│   │       │   ├── _SUCCESS
│   │       │   └── part-00000-b4013caa-19ef-4a5c-af0e-d019a0f7820f-c000.csv
│   │       ├── predictions.parquet/
│   │       │   ├── _SUCCESS
│   │       │   └── part-00000-80b43bb9-652d-4397-96de-f34e44baa54e-c000.snappy.parquet
│   │       └── top50_reviews_csv/
│   │           ├── _SUCCESS
│   │           └── part-00000-442b074b-99b8-4fbe-ab8b-7466f6cbcbdf-c000.csv
│   └── viz/
│       ├── aspect_opportunity_bubble.html
│       ├── market_brand_bubbles.html
│       ├── market_brand_panel_sticky.html
│       ├── negatives_excess_heatmap.html
│       ├── negatives_table.csv
│       ├── simple_labels_all.csv
│       ├── simple_top_risks_by_category.csv
│       ├── simple_top_risks_overall.csv
│       ├── simple_top_strengths_by_category.csv
│       ├── simple_top_strengths_overall.csv
│       ├── top_brand_per_category_aspect.csv
│       └── violin_secondary_rating.html
├── requirements.txt
├── scripts/
│   ├── EDA/
│   │   ├── eda_compare.py
│   │   └── eda_reviews.py
│   ├── absa/
│   │   ├── absa_insights_altair.py
│   │   ├── build_absa_dataset.py
│   │   ├── build_ate_trusted_from_ontology.py
│   │   ├── build_preview_fused.py
│   │   ├── build_product_cards.py
│   │   ├── compute_product_rating_stats.py
│   │   ├── debug_inspect_radar.py
│   │   ├── download_product_thumbs.py
│   │   ├── export_product_info_snapshot.py
│   │   ├── fetch_product_images.py
│   │   ├── infer_ate_spans.py
│   │   ├── inject_recalculated_ratings.py
│   │   ├── make_absa_report.py
│   │   ├── make_product_cards_html.py
│   │   ├── map_spans_to_ontology.py
│   │   ├── top10_loves_duckdb.py
│   │   └── train_ate_bio.py
│   ├── data_cleaning/
│   │   ├── conversion_a_delta.py
│   │   ├── make_rest_from_full.py
│   │   ├── merge_reviews_product_info.py
│   │   ├── merge_trusted_reviews.py
│   │   ├── sample_reviews.py
│   │   ├── trusted_clean_driver.py
│   │   ├── trusted_clean_single.py
│   │   └── utils_text.py
│   ├── data_ingestion/
│   │   └── descarga_kaggle_reviews.py
│   ├── data_integration/
│   ├── evaluation/
│   │   ├── check_rf_inputs.py
│   │   ├── merge_parquets.py*
│   │   ├── metrics_overall.py*
│   │   └── metrics_partitions.py*
│   ├── infer/
│   │   ├── convert_delta_to_parquet_snapshot.py
│   │   ├── infer_sentiment_full_pandas.py
│   │   └── infer_top_upvoted_ulta.py
│   ├── setup/
│   │   ├── dvc_run.sh*
│   │   ├── setup_dvc_remote.sh
│   │   └── verificar_dvc.sh*
│   ├── training/
│   │   ├── __pycache__/
│   │   │   └── train_random_forest.cpython-310.pyc
│   │   ├── evaluate_albert.py
│   │   ├── infer_random_forest.py
│   │   ├── prepare_test_parquet.py
│   │   ├── split_train_val_test.py
│   │   ├── train_albert_from_parquets.py
│   │   └── train_random_forest.py
│   └── viz/
│       ├── aspect_opportunity.py
│       ├── cards_index_with_filters.py
│       ├── compute_top_brand_per_aspect_from_preview.py
│       ├── deep_dive_reviews.py
│       ├── ingredients_differential.py
│       ├── link_top10_cards.py
│       ├── make_priority_tables_simple.py
│       ├── viz_box_from_preview.py
│       ├── viz_market_brand_bubbles.py
│       ├── viz_market_brand_panel.py
│       ├── viz_ridge_from_preview.py
│       └── viz_violin_secondary_rating.py
├── scripts.zip
├── tests/
├── tree.txt
└── tree_full_tfm.txt

440 directories, 10778 files
